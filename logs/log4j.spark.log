17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 847
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:60738 in memory (size: 9.4 KB, free: 338.4 MB)
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:60738 in memory (size: 8.7 KB, free: 338.4 MB)
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:60738 in memory (size: 14.2 KB, free: 338.4 MB)
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:60738 in memory (size: 6.2 KB, free: 338.4 MB)
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:60738 in memory (size: 11.7 KB, free: 338.4 MB)
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 1897
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 1898
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:60738 in memory (size: 12.7 KB, free: 338.4 MB)
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 846
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 845
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 844
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 843
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 842
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 841
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:60738 in memory (size: 12.5 KB, free: 338.5 MB)
17/11/20 00:14:23 INFO ContextCleaner: Cleaned shuffle 2
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 338
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 337
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 336
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 335
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 334
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 333
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 332
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 331
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 330
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 329
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 328
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 327
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:60738 in memory (size: 20.8 KB, free: 338.5 MB)
17/11/20 00:14:23 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:60738 in memory (size: 12.9 KB, free: 338.5 MB)
17/11/20 00:14:23 INFO ContextCleaner: Cleaned shuffle 4
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 852
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 851
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 850
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 849
17/11/20 00:14:23 INFO ContextCleaner: Cleaned accumulator 848
17/11/20 00:34:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:34:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:34:50 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:34:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:34:50 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:34:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:34:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:34:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:34:50 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 00:34:50 INFO DAGScheduler: Got job 19 (collect at utils.scala:58) with 1 output partitions
17/11/20 00:34:50 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:58)
17/11/20 00:34:50 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:34:50 INFO DAGScheduler: Missing parents: List()
17/11/20 00:34:50 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[126] at map at utils.scala:55), which has no missing parents
17/11/20 00:34:50 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 8.7 KB, free 337.6 MB)
17/11/20 00:34:50 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 4.6 KB, free 337.6 MB)
17/11/20 00:34:50 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:60738 (size: 4.6 KB, free: 338.5 MB)
17/11/20 00:34:50 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/11/20 00:34:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[126] at map at utils.scala:55)
17/11/20 00:34:50 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/11/20 00:34:50 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 6462 bytes)
17/11/20 00:34:50 INFO Executor: Running task 0.0 in stage 30.0 (TID 58)
17/11/20 00:34:50 INFO Executor: Finished task 0.0 in stage 30.0 (TID 58). 1345 bytes result sent to driver
17/11/20 00:34:50 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 58) in 42 ms on localhost (executor driver) (1/1)
17/11/20 00:34:50 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/11/20 00:34:50 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:58) finished in 0.043 s
17/11/20 00:34:50 INFO DAGScheduler: Job 19 finished: collect at utils.scala:58, took 0.069557 s
17/11/20 00:34:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:34:50 INFO SparkSqlParser: Parsing command: mtcars
17/11/20 00:34:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:34:50 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
17/11/20 00:34:50 INFO SparkSqlParser: Parsing command: `mtcars`
17/11/20 00:34:50 INFO FileSourceStrategy: Pruning directories with: 
17/11/20 00:34:50 INFO FileSourceStrategy: Post-Scan Filters: 
17/11/20 00:34:50 INFO FileSourceStrategy: Output Data Schema: struct<mpg: double, cyl: double, disp: double, hp: double, drat: double ... 9 more fields>
17/11/20 00:34:50 INFO FileSourceStrategy: Pushed Filters: 
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 290.9 KB, free 337.3 MB)
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 23.7 KB, free 337.3 MB)
17/11/20 00:34:51 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:60738 (size: 23.7 KB, free: 338.5 MB)
17/11/20 00:34:51 INFO SparkContext: Created broadcast 34 from sql at NativeMethodAccessorImpl.java:0
17/11/20 00:34:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/11/20 00:34:51 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/11/20 00:34:51 INFO DAGScheduler: Registering RDD 133 (sql at NativeMethodAccessorImpl.java:0)
17/11/20 00:34:51 INFO DAGScheduler: Got job 20 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:34:51 INFO DAGScheduler: Final stage: ResultStage 32 (sql at NativeMethodAccessorImpl.java:0)
17/11/20 00:34:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
17/11/20 00:34:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
17/11/20 00:34:51 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[133] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 23.2 KB, free 337.3 MB)
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 11.0 KB, free 337.3 MB)
17/11/20 00:34:51 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:60738 (size: 11.0 KB, free: 338.5 MB)
17/11/20 00:34:51 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/11/20 00:34:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[133] at sql at NativeMethodAccessorImpl.java:0)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/11/20 00:34:51 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 6692 bytes)
17/11/20 00:34:51 INFO Executor: Running task 0.0 in stage 31.0 (TID 59)
17/11/20 00:34:51 INFO FileScanRDD: Reading File path: file:///var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/spark_serialize_600df8759318fe0d3e7cd227dfb889264b9395236a2336b9c1d32f83ed509279.csv, range: 0-1303, partition values: [empty row]
17/11/20 00:34:51 INFO CodeGenerator: Code generated in 23.957346 ms
17/11/20 00:34:51 INFO MemoryStore: Block rdd_130_0 stored as values in memory (estimated size 4.2 KB, free 337.3 MB)
17/11/20 00:34:51 INFO BlockManagerInfo: Added rdd_130_0 in memory on 127.0.0.1:60738 (size: 4.2 KB, free: 338.4 MB)
17/11/20 00:34:51 INFO Executor: Finished task 0.0 in stage 31.0 (TID 59). 2910 bytes result sent to driver
17/11/20 00:34:51 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 59) in 64 ms on localhost (executor driver) (1/1)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/11/20 00:34:51 INFO DAGScheduler: ShuffleMapStage 31 (sql at NativeMethodAccessorImpl.java:0) finished in 0.065 s
17/11/20 00:34:51 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:34:51 INFO DAGScheduler: running: Set()
17/11/20 00:34:51 INFO DAGScheduler: waiting: Set(ResultStage 32)
17/11/20 00:34:51 INFO DAGScheduler: failed: Set()
17/11/20 00:34:51 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[136] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.0 KB, free 337.3 MB)
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 337.3 MB)
17/11/20 00:34:51 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:34:51 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/11/20 00:34:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[136] at sql at NativeMethodAccessorImpl.java:0)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/11/20 00:34:51 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 60, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/11/20 00:34:51 INFO Executor: Running task 0.0 in stage 32.0 (TID 60)
17/11/20 00:34:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:34:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:34:51 INFO Executor: Finished task 0.0 in stage 32.0 (TID 60). 2042 bytes result sent to driver
17/11/20 00:34:51 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 60) in 10 ms on localhost (executor driver) (1/1)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/11/20 00:34:51 INFO DAGScheduler: ResultStage 32 (sql at NativeMethodAccessorImpl.java:0) finished in 0.011 s
17/11/20 00:34:51 INFO DAGScheduler: Job 20 finished: sql at NativeMethodAccessorImpl.java:0, took 0.127915 s
17/11/20 00:34:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:34:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
17/11/20 00:34:51 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 00:34:51 INFO DAGScheduler: Registering RDD 140 (collect at utils.scala:210)
17/11/20 00:34:51 INFO DAGScheduler: Got job 21 (collect at utils.scala:210) with 1 output partitions
17/11/20 00:34:51 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:210)
17/11/20 00:34:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
17/11/20 00:34:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
17/11/20 00:34:51 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[140] at collect at utils.scala:210), which has no missing parents
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 23.2 KB, free 337.2 MB)
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 11.0 KB, free 337.2 MB)
17/11/20 00:34:51 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:60738 (size: 11.0 KB, free: 338.4 MB)
17/11/20 00:34:51 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
17/11/20 00:34:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[140] at collect at utils.scala:210)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
17/11/20 00:34:51 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 6684 bytes)
17/11/20 00:34:51 INFO Executor: Running task 0.0 in stage 33.0 (TID 61)
17/11/20 00:34:51 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:34:51 INFO Executor: Finished task 0.0 in stage 33.0 (TID 61). 2188 bytes result sent to driver
17/11/20 00:34:51 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 61) in 13 ms on localhost (executor driver) (1/1)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/11/20 00:34:51 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:210) finished in 0.014 s
17/11/20 00:34:51 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:34:51 INFO DAGScheduler: running: Set()
17/11/20 00:34:51 INFO DAGScheduler: waiting: Set(ResultStage 34)
17/11/20 00:34:51 INFO DAGScheduler: failed: Set()
17/11/20 00:34:51 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[143] at collect at utils.scala:210), which has no missing parents
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 7.0 KB, free 337.2 MB)
17/11/20 00:34:51 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.7 KB, free 337.2 MB)
17/11/20 00:34:51 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:34:51 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/11/20 00:34:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[143] at collect at utils.scala:210)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
17/11/20 00:34:51 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 62, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/11/20 00:34:51 INFO Executor: Running task 0.0 in stage 34.0 (TID 62)
17/11/20 00:34:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:34:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/11/20 00:34:51 INFO Executor: Finished task 0.0 in stage 34.0 (TID 62). 2042 bytes result sent to driver
17/11/20 00:34:51 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 62) in 7 ms on localhost (executor driver) (1/1)
17/11/20 00:34:51 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
17/11/20 00:34:51 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:210) finished in 0.007 s
17/11/20 00:34:51 INFO DAGScheduler: Job 21 finished: collect at utils.scala:210, took 0.048422 s
17/11/20 00:34:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:34:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz5`
WHERE (0 = 1)
17/11/20 00:34:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:34:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:34:51 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:34:51 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:34:51 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:34:51 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:34:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:34:51 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:35:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:35:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:35:05 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:35:05 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:35:05 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:35:05 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:35:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:35:05 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:35:05 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 00:35:05 INFO DAGScheduler: Got job 22 (collect at utils.scala:58) with 1 output partitions
17/11/20 00:35:05 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:58)
17/11/20 00:35:05 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:35:05 INFO DAGScheduler: Missing parents: List()
17/11/20 00:35:05 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[150] at map at utils.scala:55), which has no missing parents
17/11/20 00:35:05 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 8.7 KB, free 337.2 MB)
17/11/20 00:35:05 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 4.6 KB, free 337.2 MB)
17/11/20 00:35:05 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:60738 (size: 4.6 KB, free: 338.4 MB)
17/11/20 00:35:05 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
17/11/20 00:35:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[150] at map at utils.scala:55)
17/11/20 00:35:05 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
17/11/20 00:35:05 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 6515 bytes)
17/11/20 00:35:05 INFO Executor: Running task 0.0 in stage 35.0 (TID 63)
17/11/20 00:35:05 INFO Executor: Finished task 0.0 in stage 35.0 (TID 63). 1267 bytes result sent to driver
17/11/20 00:35:05 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 63) in 6 ms on localhost (executor driver) (1/1)
17/11/20 00:35:05 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
17/11/20 00:35:05 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:58) finished in 0.006 s
17/11/20 00:35:05 INFO DAGScheduler: Job 22 finished: collect at utils.scala:58, took 0.018179 s
17/11/20 00:35:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:35:44 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
17/11/20 00:35:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_12dc02c8e3a
17/11/20 00:35:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:35:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc02c8e3a` AS `zzz6`
WHERE (0 = 1)
17/11/20 00:35:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_12dc06d2d81ec
17/11/20 00:35:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:35:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc06d2d81ec` AS `zzz7`
WHERE (0 = 1)
17/11/20 00:36:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:36:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc02c8e3a`
17/11/20 00:36:44 INFO InMemoryTableScanExec: Predicate isnotnull(hp#2035) generates partition filter: ((hp.count#2483 - hp.nullCount#2482) > 0)
17/11/20 00:36:44 INFO InMemoryTableScanExec: Predicate (hp#2035 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2480)
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 63.778806 ms
17/11/20 00:36:44 INFO SparkContext: Starting job: first at LinearRegression.scala:198
17/11/20 00:36:44 INFO DAGScheduler: Got job 23 (first at LinearRegression.scala:198) with 1 output partitions
17/11/20 00:36:44 INFO DAGScheduler: Final stage: ResultStage 36 (first at LinearRegression.scala:198)
17/11/20 00:36:44 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:36:44 INFO DAGScheduler: Missing parents: List()
17/11/20 00:36:44 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[155] at first at LinearRegression.scala:198), which has no missing parents
17/11/20 00:36:44 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 42.1 KB, free 337.2 MB)
17/11/20 00:36:44 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.8 KB, free 337.2 MB)
17/11/20 00:36:44 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:60738 (size: 17.8 KB, free: 338.4 MB)
17/11/20 00:36:44 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[155] at first at LinearRegression.scala:198)
17/11/20 00:36:44 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
17/11/20 00:36:44 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 6609 bytes)
17/11/20 00:36:44 INFO Executor: Running task 0.0 in stage 36.0 (TID 64)
17/11/20 00:36:44 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 11.973408 ms
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 21.091321 ms
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 25.850024 ms
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 16.677522 ms
17/11/20 00:36:44 INFO Executor: Finished task 0.0 in stage 36.0 (TID 64). 2184 bytes result sent to driver
17/11/20 00:36:44 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 64) in 152 ms on localhost (executor driver) (1/1)
17/11/20 00:36:44 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
17/11/20 00:36:44 INFO DAGScheduler: ResultStage 36 (first at LinearRegression.scala:198) finished in 0.152 s
17/11/20 00:36:44 INFO DAGScheduler: Job 23 finished: first at LinearRegression.scala:198, took 0.166905 s
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 8.563673 ms
17/11/20 00:36:44 INFO InMemoryTableScanExec: Predicate isnotnull(hp#2035) generates partition filter: ((hp.count#2544 - hp.nullCount#2543) > 0)
17/11/20 00:36:44 INFO InMemoryTableScanExec: Predicate (hp#2035 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2541)
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 40.389291 ms
17/11/20 00:36:44 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
17/11/20 00:36:44 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
17/11/20 00:36:44 INFO DAGScheduler: Got job 24 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
17/11/20 00:36:44 INFO DAGScheduler: Final stage: ResultStage 37 (treeAggregate at WeightedLeastSquares.scala:100)
17/11/20 00:36:44 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:36:44 INFO DAGScheduler: Missing parents: List()
17/11/20 00:36:44 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[161] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
17/11/20 00:36:44 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 45.4 KB, free 337.1 MB)
17/11/20 00:36:44 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 19.3 KB, free 337.1 MB)
17/11/20 00:36:44 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:60738 (size: 19.3 KB, free: 338.4 MB)
17/11/20 00:36:44 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[161] at treeAggregate at WeightedLeastSquares.scala:100)
17/11/20 00:36:44 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
17/11/20 00:36:44 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 6671 bytes)
17/11/20 00:36:44 INFO Executor: Running task 0.0 in stage 37.0 (TID 65)
17/11/20 00:36:44 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:36:44 INFO CodeGenerator: Code generated in 8.864642 ms
17/11/20 00:36:44 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
17/11/20 00:36:44 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
17/11/20 00:36:44 INFO Executor: Finished task 0.0 in stage 37.0 (TID 65). 2669 bytes result sent to driver
17/11/20 00:36:44 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 65) in 59 ms on localhost (executor driver) (1/1)
17/11/20 00:36:44 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
17/11/20 00:36:44 INFO DAGScheduler: ResultStage 37 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0.059 s
17/11/20 00:36:44 INFO DAGScheduler: Job 24 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0.077364 s
17/11/20 00:36:44 INFO WeightedLeastSquares: Number of instances: 8.
17/11/20 00:36:44 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
17/11/20 00:36:44 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2274
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2275
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:60738 in memory (size: 4.6 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2328
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2329
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2330
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2331
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2332
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2333
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2334
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2335
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2336
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2337
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2338
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2339
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2340
17/11/20 00:36:45 INFO ContextCleaner: Cleaned shuffle 11
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:60738 in memory (size: 11.0 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2437
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:60738 in memory (size: 11.0 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2546
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2547
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:60738 in memory (size: 4.6 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO InMemoryTableScanExec: Predicate isnotnull(hp#2035) generates partition filter: ((hp.count#2621 - hp.nullCount#2620) > 0)
17/11/20 00:36:45 INFO InMemoryTableScanExec: Predicate (hp#2035 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2618)
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2596
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2597
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2598
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2599
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2600
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2601
17/11/20 00:36:45 INFO ContextCleaner: Cleaned accumulator 2602
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:60738 in memory (size: 17.8 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:60738 in memory (size: 19.3 KB, free: 338.5 MB)
17/11/20 00:36:45 INFO CodeGenerator: Code generated in 19.552439 ms
17/11/20 00:36:45 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
17/11/20 00:36:45 INFO DAGScheduler: Got job 25 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
17/11/20 00:36:45 INFO DAGScheduler: Final stage: ResultStage 38 (aggregate at RegressionMetrics.scala:57)
17/11/20 00:36:45 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:36:45 INFO DAGScheduler: Missing parents: List()
17/11/20 00:36:45 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[167] at map at RegressionMetrics.scala:55), which has no missing parents
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 45.5 KB, free 337.3 MB)
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 19.8 KB, free 337.3 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:60738 (size: 19.8 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[167] at map at RegressionMetrics.scala:55)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
17/11/20 00:36:45 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 6667 bytes)
17/11/20 00:36:45 INFO Executor: Running task 0.0 in stage 38.0 (TID 66)
17/11/20 00:36:45 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:36:45 INFO CodeGenerator: Code generated in 5.019078 ms
17/11/20 00:36:45 INFO Executor: Finished task 0.0 in stage 38.0 (TID 66). 2621 bytes result sent to driver
17/11/20 00:36:45 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 66) in 37 ms on localhost (executor driver) (1/1)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
17/11/20 00:36:45 INFO DAGScheduler: ResultStage 38 (aggregate at RegressionMetrics.scala:57) finished in 0.038 s
17/11/20 00:36:45 INFO DAGScheduler: Job 25 finished: aggregate at RegressionMetrics.scala:57, took 0.044689 s
17/11/20 00:36:45 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
17/11/20 00:36:45 INFO DAGScheduler: Got job 26 (sum at RegressionMetrics.scala:71) with 1 output partitions
17/11/20 00:36:45 INFO DAGScheduler: Final stage: ResultStage 39 (sum at RegressionMetrics.scala:71)
17/11/20 00:36:45 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:36:45 INFO DAGScheduler: Missing parents: List()
17/11/20 00:36:45 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[168] at map at RegressionMetrics.scala:69), which has no missing parents
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 45.1 KB, free 337.2 MB)
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.7 KB, free 337.2 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:60738 (size: 19.7 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[168] at map at RegressionMetrics.scala:69)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/11/20 00:36:45 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 6661 bytes)
17/11/20 00:36:45 INFO Executor: Running task 0.0 in stage 39.0 (TID 67)
17/11/20 00:36:45 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:36:45 INFO Executor: Finished task 0.0 in stage 39.0 (TID 67). 2138 bytes result sent to driver
17/11/20 00:36:45 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 67) in 12 ms on localhost (executor driver) (1/1)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/11/20 00:36:45 INFO DAGScheduler: ResultStage 39 (sum at RegressionMetrics.scala:71) finished in 0.012 s
17/11/20 00:36:45 INFO DAGScheduler: Job 26 finished: sum at RegressionMetrics.scala:71, took 0.018648 s
17/11/20 00:36:45 INFO InMemoryTableScanExec: Predicate isnotnull(hp#2035) generates partition filter: ((hp.count#2696 - hp.nullCount#2695) > 0)
17/11/20 00:36:45 INFO InMemoryTableScanExec: Predicate (hp#2035 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2693)
17/11/20 00:36:45 INFO CodeGenerator: Code generated in 22.543734 ms
17/11/20 00:36:45 INFO SparkContext: Starting job: count at LinearRegression.scala:683
17/11/20 00:36:45 INFO DAGScheduler: Registering RDD 171 (count at LinearRegression.scala:683)
17/11/20 00:36:45 INFO DAGScheduler: Got job 27 (count at LinearRegression.scala:683) with 1 output partitions
17/11/20 00:36:45 INFO DAGScheduler: Final stage: ResultStage 41 (count at LinearRegression.scala:683)
17/11/20 00:36:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
17/11/20 00:36:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
17/11/20 00:36:45 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[171] at count at LinearRegression.scala:683), which has no missing parents
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 37.7 KB, free 337.2 MB)
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.6 KB, free 337.1 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:60738 (size: 16.6 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[171] at count at LinearRegression.scala:683)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
17/11/20 00:36:45 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 6684 bytes)
17/11/20 00:36:45 INFO Executor: Running task 0.0 in stage 40.0 (TID 68)
17/11/20 00:36:45 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:36:45 INFO Executor: Finished task 0.0 in stage 40.0 (TID 68). 2856 bytes result sent to driver
17/11/20 00:36:45 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 68) in 25 ms on localhost (executor driver) (1/1)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
17/11/20 00:36:45 INFO DAGScheduler: ShuffleMapStage 40 (count at LinearRegression.scala:683) finished in 0.025 s
17/11/20 00:36:45 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:36:45 INFO DAGScheduler: running: Set()
17/11/20 00:36:45 INFO DAGScheduler: waiting: Set(ResultStage 41)
17/11/20 00:36:45 INFO DAGScheduler: failed: Set()
17/11/20 00:36:45 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[174] at count at LinearRegression.scala:683), which has no missing parents
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 337.1 MB)
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 337.1 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[174] at count at LinearRegression.scala:683)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
17/11/20 00:36:45 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 69, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/11/20 00:36:45 INFO Executor: Running task 0.0 in stage 41.0 (TID 69)
17/11/20 00:36:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:36:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:36:45 INFO Executor: Finished task 0.0 in stage 41.0 (TID 69). 2042 bytes result sent to driver
17/11/20 00:36:45 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 69) in 5 ms on localhost (executor driver) (1/1)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/11/20 00:36:45 INFO DAGScheduler: ResultStage 41 (count at LinearRegression.scala:683) finished in 0.005 s
17/11/20 00:36:45 INFO DAGScheduler: Job 27 finished: count at LinearRegression.scala:683, took 0.039909 s
17/11/20 00:36:45 INFO InMemoryTableScanExec: Predicate isnotnull(hp#2035) generates partition filter: ((hp.count#2764 - hp.nullCount#2763) > 0)
17/11/20 00:36:45 INFO InMemoryTableScanExec: Predicate (hp#2035 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2761)
17/11/20 00:36:45 INFO CodeGenerator: Code generated in 14.191718 ms
17/11/20 00:36:45 INFO CodeGenerator: Code generated in 31.377553 ms
17/11/20 00:36:45 INFO SparkContext: Starting job: first at LinearRegression.scala:707
17/11/20 00:36:45 INFO DAGScheduler: Registering RDD 177 (first at LinearRegression.scala:707)
17/11/20 00:36:45 INFO DAGScheduler: Got job 28 (first at LinearRegression.scala:707) with 1 output partitions
17/11/20 00:36:45 INFO DAGScheduler: Final stage: ResultStage 43 (first at LinearRegression.scala:707)
17/11/20 00:36:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
17/11/20 00:36:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
17/11/20 00:36:45 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[177] at first at LinearRegression.scala:707), which has no missing parents
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 52.0 KB, free 337.1 MB)
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 22.5 KB, free 337.1 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:60738 (size: 22.5 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[177] at first at LinearRegression.scala:707)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
17/11/20 00:36:45 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 6598 bytes)
17/11/20 00:36:45 INFO Executor: Running task 0.0 in stage 42.0 (TID 70)
17/11/20 00:36:45 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:36:45 INFO Executor: Finished task 0.0 in stage 42.0 (TID 70). 2856 bytes result sent to driver
17/11/20 00:36:45 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 70) in 23 ms on localhost (executor driver) (1/1)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
17/11/20 00:36:45 INFO DAGScheduler: ShuffleMapStage 42 (first at LinearRegression.scala:707) finished in 0.023 s
17/11/20 00:36:45 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:36:45 INFO DAGScheduler: running: Set()
17/11/20 00:36:45 INFO DAGScheduler: waiting: Set(ResultStage 43)
17/11/20 00:36:45 INFO DAGScheduler: failed: Set()
17/11/20 00:36:45 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[180] at first at LinearRegression.scala:707), which has no missing parents
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 7.9 KB, free 337.1 MB)
17/11/20 00:36:45 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 4.0 KB, free 337.1 MB)
17/11/20 00:36:45 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:60738 (size: 4.0 KB, free: 338.4 MB)
17/11/20 00:36:45 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
17/11/20 00:36:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[180] at first at LinearRegression.scala:707)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
17/11/20 00:36:45 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 71, localhost, executor driver, partition 0, ANY, 5861 bytes)
17/11/20 00:36:45 INFO Executor: Running task 0.0 in stage 43.0 (TID 71)
17/11/20 00:36:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:36:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:36:45 INFO Executor: Finished task 0.0 in stage 43.0 (TID 71). 2027 bytes result sent to driver
17/11/20 00:36:45 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 71) in 6 ms on localhost (executor driver) (1/1)
17/11/20 00:36:45 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
17/11/20 00:36:45 INFO DAGScheduler: ResultStage 43 (first at LinearRegression.scala:707) finished in 0.006 s
17/11/20 00:36:45 INFO DAGScheduler: Job 28 finished: first at LinearRegression.scala:707, took 0.039582 s
17/11/20 00:36:45 INFO SparkSqlParser: Parsing command: sparklyr_tmp_12dc0733566d4
17/11/20 00:36:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:36:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc0733566d4` AS `zzz8`
WHERE (0 = 1)
17/11/20 00:36:45 INFO SparkSqlParser: Parsing command: sparklyr_tmp_12dc036f22363
17/11/20 00:36:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:36:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc036f22363` AS `zzz9`
WHERE (0 = 1)
17/11/20 00:36:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:36:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc02c8e3a`
17/11/20 00:36:46 INFO SparkSqlParser: Parsing command: sparklyr_tmp_12dc052f154c3
17/11/20 00:36:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:36:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc052f154c3` AS `zzz10`
WHERE (0 = 1)
17/11/20 00:36:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:36:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc052f154c3`
17/11/20 00:37:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:37:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc036f22363`
17/11/20 00:37:08 INFO InMemoryTableScanExec: Predicate isnotnull(hp#2035) generates partition filter: ((hp.count#2971 - hp.nullCount#2970) > 0)
17/11/20 00:37:08 INFO InMemoryTableScanExec: Predicate (hp#2035 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2968)
17/11/20 00:37:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/11/20 00:37:08 INFO DAGScheduler: Registering RDD 186 (count at NativeMethodAccessorImpl.java:0)
17/11/20 00:37:08 INFO DAGScheduler: Got job 29 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:37:08 INFO DAGScheduler: Final stage: ResultStage 45 (count at NativeMethodAccessorImpl.java:0)
17/11/20 00:37:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
17/11/20 00:37:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
17/11/20 00:37:08 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[186] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:37:08 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 37.7 KB, free 337.0 MB)
17/11/20 00:37:08 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 16.5 KB, free 337.0 MB)
17/11/20 00:37:08 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:60738 (size: 16.5 KB, free: 338.4 MB)
17/11/20 00:37:08 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
17/11/20 00:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[186] at count at NativeMethodAccessorImpl.java:0)
17/11/20 00:37:08 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
17/11/20 00:37:08 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 6684 bytes)
17/11/20 00:37:08 INFO Executor: Running task 0.0 in stage 44.0 (TID 72)
17/11/20 00:37:08 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:37:08 INFO Executor: Finished task 0.0 in stage 44.0 (TID 72). 2856 bytes result sent to driver
17/11/20 00:37:08 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 72) in 14 ms on localhost (executor driver) (1/1)
17/11/20 00:37:08 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
17/11/20 00:37:08 INFO DAGScheduler: ShuffleMapStage 44 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s
17/11/20 00:37:08 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:37:08 INFO DAGScheduler: running: Set()
17/11/20 00:37:08 INFO DAGScheduler: waiting: Set(ResultStage 45)
17/11/20 00:37:08 INFO DAGScheduler: failed: Set()
17/11/20 00:37:08 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[189] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:37:08 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 7.0 KB, free 337.0 MB)
17/11/20 00:37:08 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.7 KB, free 337.0 MB)
17/11/20 00:37:08 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:37:08 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
17/11/20 00:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[189] at count at NativeMethodAccessorImpl.java:0)
17/11/20 00:37:08 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
17/11/20 00:37:08 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 73, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/11/20 00:37:08 INFO Executor: Running task 0.0 in stage 45.0 (TID 73)
17/11/20 00:37:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:37:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:37:08 INFO Executor: Finished task 0.0 in stage 45.0 (TID 73). 2042 bytes result sent to driver
17/11/20 00:37:08 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 73) in 5 ms on localhost (executor driver) (1/1)
17/11/20 00:37:08 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
17/11/20 00:37:08 INFO DAGScheduler: ResultStage 45 (count at NativeMethodAccessorImpl.java:0) finished in 0.005 s
17/11/20 00:37:08 INFO DAGScheduler: Job 29 finished: count at NativeMethodAccessorImpl.java:0, took 0.032144 s
17/11/20 00:37:08 INFO InMemoryTableScanExec: Predicate isnotnull(hp#2035) generates partition filter: ((hp.count#3031 - hp.nullCount#3030) > 0)
17/11/20 00:37:08 INFO InMemoryTableScanExec: Predicate (hp#2035 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#3028)
17/11/20 00:37:08 INFO CodeGenerator: Code generated in 32.771894 ms
17/11/20 00:37:08 INFO SparkContext: Starting job: collect at utils.scala:51
17/11/20 00:37:08 INFO DAGScheduler: Got job 30 (collect at utils.scala:51) with 1 output partitions
17/11/20 00:37:08 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:51)
17/11/20 00:37:08 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:37:08 INFO DAGScheduler: Missing parents: List()
17/11/20 00:37:08 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[194] at map at utils.scala:48), which has no missing parents
17/11/20 00:37:08 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 51.8 KB, free 336.9 MB)
17/11/20 00:37:08 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 21.3 KB, free 336.9 MB)
17/11/20 00:37:08 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:60738 (size: 21.3 KB, free: 338.3 MB)
17/11/20 00:37:08 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
17/11/20 00:37:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[194] at map at utils.scala:48)
17/11/20 00:37:08 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
17/11/20 00:37:08 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 6665 bytes)
17/11/20 00:37:08 INFO Executor: Running task 0.0 in stage 46.0 (TID 74)
17/11/20 00:37:08 INFO BlockManager: Found block rdd_130_0 locally
17/11/20 00:37:08 INFO CodeGenerator: Code generated in 4.388991 ms
17/11/20 00:37:08 INFO Executor: Finished task 0.0 in stage 46.0 (TID 74). 2145 bytes result sent to driver
17/11/20 00:37:08 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 74) in 20 ms on localhost (executor driver) (1/1)
17/11/20 00:37:08 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
17/11/20 00:37:08 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:51) finished in 0.021 s
17/11/20 00:37:08 INFO DAGScheduler: Job 30 finished: collect at utils.scala:51, took 0.028722 s
17/11/20 00:43:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
17/11/20 00:43:14 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/11/20 00:43:14 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/11/20 00:43:14 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/11/20 00:43:14 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/11/20 00:43:14 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/11/20 00:43:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
17/11/20 00:43:14 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/11/20 00:43:14 INFO DAGScheduler: Got job 31 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:43:14 INFO DAGScheduler: Final stage: ResultStage 47 (csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:14 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:14 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:14 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[195] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:14 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 87.7 KB, free 336.8 MB)
17/11/20 00:43:14 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 34.3 KB, free 336.8 MB)
17/11/20 00:43:14 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:60738 (size: 34.3 KB, free: 338.3 MB)
17/11/20 00:43:14 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[195] at csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:14 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
17/11/20 00:43:14 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 6703 bytes)
17/11/20 00:43:14 INFO Executor: Running task 0.0 in stage 47.0 (TID 75)
17/11/20 00:43:14 INFO BlockManager: Found block rdd_11_0 locally
17/11/20 00:43:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
17/11/20 00:43:14 INFO FileOutputCommitter: Saved output of task 'attempt_20171120004314_0047_m_000000_0' to file:/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc06994e1e5.csv/_temporary/0/task_20171120004314_0047_m_000000
17/11/20 00:43:14 INFO SparkHadoopMapRedUtil: attempt_20171120004314_0047_m_000000_0: Committed
17/11/20 00:43:14 INFO Executor: Finished task 0.0 in stage 47.0 (TID 75). 1845 bytes result sent to driver
17/11/20 00:43:14 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 75) in 99 ms on localhost (executor driver) (1/1)
17/11/20 00:43:14 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
17/11/20 00:43:14 INFO DAGScheduler: ResultStage 47 (csv at NativeMethodAccessorImpl.java:0) finished in 0.099 s
17/11/20 00:43:14 INFO DAGScheduler: Job 31 finished: csv at NativeMethodAccessorImpl.java:0, took 0.124070 s
17/11/20 00:43:14 INFO FileFormatWriter: Job null committed.
17/11/20 00:43:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:20 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 00:43:20 INFO DAGScheduler: Got job 32 (collect at utils.scala:58) with 1 output partitions
17/11/20 00:43:20 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:58)
17/11/20 00:43:20 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:20 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:20 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[202] at map at utils.scala:55), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 8.7 KB, free 336.8 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 4.6 KB, free 336.8 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:60738 (size: 4.6 KB, free: 338.3 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[202] at map at utils.scala:55)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 6878 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 48.0 (TID 76)
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 48.0 (TID 76). 1410 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 76) in 5 ms on localhost (executor driver) (1/1)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:58) finished in 0.007 s
17/11/20 00:43:20 INFO DAGScheduler: Job 32 finished: collect at utils.scala:58, took 0.015022 s
17/11/20 00:43:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:60738 in memory (size: 4.6 KB, free: 338.3 MB)
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2651
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2652
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2653
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2654
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2655
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2656
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2657
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:60738 in memory (size: 19.8 KB, free: 338.3 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:60738 in memory (size: 19.7 KB, free: 338.3 MB)
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2809
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2810
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2811
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2812
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2813
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2814
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2815
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2816
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2817
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2818
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2819
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2820
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2821
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2822
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2823
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2824
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2825
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2826
17/11/20 00:43:20 INFO ContextCleaner: Cleaned shuffle 13
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:60738 in memory (size: 16.6 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2923
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2924
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2925
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2926
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2927
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2928
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2929
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2930
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2931
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2932
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2933
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2934
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2935
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2936
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2937
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2938
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2939
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 2940
17/11/20 00:43:20 INFO ContextCleaner: Cleaned shuffle 14
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:60738 in memory (size: 22.5 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:60738 in memory (size: 4.0 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3037
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3038
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3039
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3040
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3041
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3042
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3043
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3044
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3045
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3046
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3047
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3048
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3049
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3050
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3051
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3052
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3053
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3054
17/11/20 00:43:20 INFO ContextCleaner: Cleaned shuffle 15
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:60738 in memory (size: 16.5 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3151
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3152
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3153
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3154
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3155
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3156
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3157
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:60738 in memory (size: 21.3 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3206
17/11/20 00:43:20 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:60738 in memory (size: 34.3 KB, free: 338.5 MB)
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3255
17/11/20 00:43:20 INFO ContextCleaner: Cleaned accumulator 3256
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 237.3 KB, free 337.1 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 23.1 KB, free 337.1 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:60738 (size: 23.1 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 53 from csv at NativeMethodAccessorImpl.java:0
17/11/20 00:43:20 INFO FileInputFormat: Total input paths to process : 1
17/11/20 00:43:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/11/20 00:43:20 INFO DAGScheduler: Got job 33 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:43:20 INFO DAGScheduler: Final stage: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:20 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:20 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:20 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[205] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 3.6 KB, free 337.1 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.2 KB, free 337.1 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:60738 (size: 2.2 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[205] at csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 6155 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 49.0 (TID 77)
17/11/20 00:43:20 INFO HadoopRDD: Input split: file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc06994e1e5.csv/part-00000-d030386f-357c-4fd9-bddd-9fbc00c5a9ce.csv:0+1929
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 49.0 (TID 77). 1145 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 77) in 26 ms on localhost (executor driver) (1/1)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0) finished in 0.026 s
17/11/20 00:43:20 INFO DAGScheduler: Job 33 finished: csv at NativeMethodAccessorImpl.java:0, took 0.031173 s
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 237.3 KB, free 336.8 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 23.1 KB, free 336.8 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:60738 (size: 23.1 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 55 from csv at NativeMethodAccessorImpl.java:0
17/11/20 00:43:20 INFO FileInputFormat: Total input paths to process : 1
17/11/20 00:43:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/11/20 00:43:20 INFO DAGScheduler: Got job 34 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:43:20 INFO DAGScheduler: Final stage: ResultStage 50 (csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:20 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:20 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:20 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[208] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 3.6 KB, free 336.8 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.2 KB, free 336.8 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:60738 (size: 2.2 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[208] at csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 6155 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 50.0 (TID 78)
17/11/20 00:43:20 INFO HadoopRDD: Input split: file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc06994e1e5.csv/part-00000-d030386f-357c-4fd9-bddd-9fbc00c5a9ce.csv:0+1929
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 50.0 (TID 78). 1145 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 78) in 8 ms on localhost (executor driver) (1/1)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ResultStage 50 (csv at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/11/20 00:43:20 INFO DAGScheduler: Job 34 finished: csv at NativeMethodAccessorImpl.java:0, took 0.012411 s
17/11/20 00:43:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/11/20 00:43:20 INFO DAGScheduler: Got job 35 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
17/11/20 00:43:20 INFO DAGScheduler: Final stage: ResultStage 51 (csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:20 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:20 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:20 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[209] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 8.0 KB, free 336.8 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.3 KB, free 336.8 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:60738 (size: 5.3 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[209] at csv at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 6159 bytes)
17/11/20 00:43:20 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 80, localhost, executor driver, partition 1, PROCESS_LOCAL, 6159 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 51.0 (TID 79)
17/11/20 00:43:20 INFO Executor: Running task 1.0 in stage 51.0 (TID 80)
17/11/20 00:43:20 INFO HadoopRDD: Input split: file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc06994e1e5.csv/part-00000-d030386f-357c-4fd9-bddd-9fbc00c5a9ce.csv:0+1929
17/11/20 00:43:20 INFO HadoopRDD: Input split: file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc06994e1e5.csv/part-00000-d030386f-357c-4fd9-bddd-9fbc00c5a9ce.csv:1929+1929
17/11/20 00:43:20 INFO Executor: Finished task 1.0 in stage 51.0 (TID 80). 1229 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 80) in 29 ms on localhost (executor driver) (1/2)
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 51.0 (TID 79). 1229 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 79) in 29 ms on localhost (executor driver) (2/2)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ResultStage 51 (csv at NativeMethodAccessorImpl.java:0) finished in 0.031 s
17/11/20 00:43:20 INFO DAGScheduler: Job 35 finished: csv at NativeMethodAccessorImpl.java:0, took 0.035996 s
17/11/20 00:43:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: iris_csv
17/11/20 00:43:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_csv`
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: `iris_csv`
17/11/20 00:43:20 INFO FileSourceStrategy: Pruning directories with: 
17/11/20 00:43:20 INFO FileSourceStrategy: Post-Scan Filters: 
17/11/20 00:43:20 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
17/11/20 00:43:20 INFO FileSourceStrategy: Pushed Filters: 
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 282.1 KB, free 336.5 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 23.9 KB, free 336.5 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:60738 (size: 23.9 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 58 from sql at <unknown>:0
17/11/20 00:43:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/11/20 00:43:20 INFO SparkContext: Starting job: sql at <unknown>:0
17/11/20 00:43:20 INFO DAGScheduler: Registering RDD 217 (sql at <unknown>:0)
17/11/20 00:43:20 INFO DAGScheduler: Got job 36 (sql at <unknown>:0) with 1 output partitions
17/11/20 00:43:20 INFO DAGScheduler: Final stage: ResultStage 53 (sql at <unknown>:0)
17/11/20 00:43:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
17/11/20 00:43:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
17/11/20 00:43:20 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[217] at sql at <unknown>:0), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 20.0 KB, free 336.5 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 10.1 KB, free 336.5 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:60738 (size: 10.1 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[217] at sql at <unknown>:0)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 6689 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 52.0 (TID 81)
17/11/20 00:43:20 INFO FileScanRDD: Reading File path: file:///private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc06994e1e5.csv/part-00000-d030386f-357c-4fd9-bddd-9fbc00c5a9ce.csv, range: 0-3858, partition values: [empty row]
17/11/20 00:43:20 INFO MemoryStore: Block rdd_214_0 stored as values in memory (estimated size 5.6 KB, free 336.5 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added rdd_214_0 in memory on 127.0.0.1:60738 (size: 5.6 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 52.0 (TID 81). 2910 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 81) in 15 ms on localhost (executor driver) (1/1)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ShuffleMapStage 52 (sql at <unknown>:0) finished in 0.015 s
17/11/20 00:43:20 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:43:20 INFO DAGScheduler: running: Set()
17/11/20 00:43:20 INFO DAGScheduler: waiting: Set(ResultStage 53)
17/11/20 00:43:20 INFO DAGScheduler: failed: Set()
17/11/20 00:43:20 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[220] at sql at <unknown>:0), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 7.0 KB, free 336.5 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.7 KB, free 336.5 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[220] at sql at <unknown>:0)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 82, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 53.0 (TID 82)
17/11/20 00:43:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 53.0 (TID 82). 1963 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 82) in 5 ms on localhost (executor driver) (1/1)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ResultStage 53 (sql at <unknown>:0) finished in 0.005 s
17/11/20 00:43:20 INFO DAGScheduler: Job 36 finished: sql at <unknown>:0, took 0.030439 s
17/11/20 00:43:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_csv`
17/11/20 00:43:20 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 00:43:20 INFO DAGScheduler: Registering RDD 224 (collect at utils.scala:210)
17/11/20 00:43:20 INFO DAGScheduler: Got job 37 (collect at utils.scala:210) with 1 output partitions
17/11/20 00:43:20 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:210)
17/11/20 00:43:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
17/11/20 00:43:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
17/11/20 00:43:20 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[224] at collect at utils.scala:210), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 20.0 KB, free 336.4 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 10.1 KB, free 336.4 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:60738 (size: 10.1 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[224] at collect at utils.scala:210)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 6681 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 54.0 (TID 83)
17/11/20 00:43:20 INFO BlockManager: Found block rdd_214_0 locally
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 54.0 (TID 83). 2188 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 83) in 7 ms on localhost (executor driver) (1/1)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ShuffleMapStage 54 (collect at utils.scala:210) finished in 0.007 s
17/11/20 00:43:20 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:43:20 INFO DAGScheduler: running: Set()
17/11/20 00:43:20 INFO DAGScheduler: waiting: Set(ResultStage 55)
17/11/20 00:43:20 INFO DAGScheduler: failed: Set()
17/11/20 00:43:20 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[227] at collect at utils.scala:210), which has no missing parents
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 7.0 KB, free 336.4 MB)
17/11/20 00:43:20 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.7 KB, free 336.4 MB)
17/11/20 00:43:20 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:43:20 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[227] at collect at utils.scala:210)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
17/11/20 00:43:20 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 84, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/11/20 00:43:20 INFO Executor: Running task 0.0 in stage 55.0 (TID 84)
17/11/20 00:43:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:43:20 INFO Executor: Finished task 0.0 in stage 55.0 (TID 84). 2042 bytes result sent to driver
17/11/20 00:43:20 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 84) in 4 ms on localhost (executor driver) (1/1)
17/11/20 00:43:20 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
17/11/20 00:43:20 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:210) finished in 0.004 s
17/11/20 00:43:20 INFO DAGScheduler: Job 37 finished: collect at utils.scala:210, took 0.019062 s
17/11/20 00:43:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_csv` AS `zzz11`
WHERE (0 = 1)
17/11/20 00:43:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:20 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
17/11/20 00:43:22 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/11/20 00:43:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/11/20 00:43:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/11/20 00:43:22 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/11/20 00:43:22 INFO DAGScheduler: Got job 38 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:43:22 INFO DAGScheduler: Final stage: ResultStage 56 (parquet at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:22 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:22 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:22 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[229] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 88.8 KB, free 336.3 MB)
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 34.6 KB, free 336.3 MB)
17/11/20 00:43:22 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:60738 (size: 34.6 KB, free: 338.3 MB)
17/11/20 00:43:22 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[229] at parquet at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:22 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
17/11/20 00:43:22 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 6703 bytes)
17/11/20 00:43:22 INFO Executor: Running task 0.0 in stage 56.0 (TID 85)
17/11/20 00:43:22 INFO BlockManager: Found block rdd_11_0 locally
17/11/20 00:43:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/11/20 00:43:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/11/20 00:43:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Sepal_Length",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "Sepal_Width",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "Petal_Length",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "Petal_Width",
    "type" : "double",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "Species",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional double Sepal_Length;
  optional double Sepal_Width;
  optional double Petal_Length;
  optional double Petal_Width;
  optional binary Species (UTF8);
}

       
17/11/20 00:43:22 INFO CodecPool: Got brand-new compressor [.snappy]
17/11/20 00:43:22 INFO FileOutputCommitter: Saved output of task 'attempt_20171120004322_0056_m_000000_0' to file:/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc02d7ab78a.parquet/_temporary/0/task_20171120004322_0056_m_000000
17/11/20 00:43:22 INFO SparkHadoopMapRedUtil: attempt_20171120004322_0056_m_000000_0: Committed
17/11/20 00:43:22 INFO Executor: Finished task 0.0 in stage 56.0 (TID 85). 1758 bytes result sent to driver
17/11/20 00:43:22 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 85) in 356 ms on localhost (executor driver) (1/1)
17/11/20 00:43:22 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
17/11/20 00:43:22 INFO DAGScheduler: ResultStage 56 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.356 s
17/11/20 00:43:22 INFO DAGScheduler: Job 38 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.375339 s
17/11/20 00:43:22 INFO FileFormatWriter: Job null committed.
17/11/20 00:43:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:22 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:22 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:22 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:22 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:22 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:22 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 00:43:22 INFO DAGScheduler: Got job 39 (collect at utils.scala:58) with 1 output partitions
17/11/20 00:43:22 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:58)
17/11/20 00:43:22 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:22 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:22 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[236] at map at utils.scala:55), which has no missing parents
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 8.7 KB, free 336.3 MB)
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.6 KB, free 336.3 MB)
17/11/20 00:43:22 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:60738 (size: 4.6 KB, free: 338.3 MB)
17/11/20 00:43:22 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[236] at map at utils.scala:55)
17/11/20 00:43:22 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
17/11/20 00:43:22 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 6933 bytes)
17/11/20 00:43:22 INFO Executor: Running task 0.0 in stage 57.0 (TID 86)
17/11/20 00:43:22 INFO Executor: Finished task 0.0 in stage 57.0 (TID 86). 1421 bytes result sent to driver
17/11/20 00:43:22 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 86) in 6 ms on localhost (executor driver) (1/1)
17/11/20 00:43:22 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
17/11/20 00:43:22 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:58) finished in 0.006 s
17/11/20 00:43:22 INFO DAGScheduler: Job 39 finished: collect at utils.scala:58, took 0.013519 s
17/11/20 00:43:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:22 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/11/20 00:43:22 INFO DAGScheduler: Got job 40 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:43:22 INFO DAGScheduler: Final stage: ResultStage 58 (parquet at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:22 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:22 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:22 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[238] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 70.7 KB, free 336.2 MB)
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 25.3 KB, free 336.2 MB)
17/11/20 00:43:22 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:60738 (size: 25.3 KB, free: 338.3 MB)
17/11/20 00:43:22 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[238] at parquet at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:22 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
17/11/20 00:43:22 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
17/11/20 00:43:22 INFO Executor: Running task 0.0 in stage 58.0 (TID 87)
17/11/20 00:43:22 INFO Executor: Finished task 0.0 in stage 58.0 (TID 87). 1898 bytes result sent to driver
17/11/20 00:43:22 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 87) in 32 ms on localhost (executor driver) (1/1)
17/11/20 00:43:22 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
17/11/20 00:43:22 INFO DAGScheduler: ResultStage 58 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.032 s
17/11/20 00:43:22 INFO DAGScheduler: Job 40 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.050102 s
17/11/20 00:43:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:22 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:22 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:22 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:22 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:22 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:22 INFO SparkSqlParser: Parsing command: iris_parquet
17/11/20 00:43:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:22 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_parquet`
17/11/20 00:43:22 INFO SparkSqlParser: Parsing command: `iris_parquet`
17/11/20 00:43:22 INFO FileSourceStrategy: Pruning directories with: 
17/11/20 00:43:22 INFO FileSourceStrategy: Post-Scan Filters: 
17/11/20 00:43:22 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
17/11/20 00:43:22 INFO FileSourceStrategy: Pushed Filters: 
17/11/20 00:43:22 INFO CodeGenerator: Code generated in 17.820571 ms
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 283.8 KB, free 335.9 MB)
17/11/20 00:43:22 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 24.3 KB, free 335.9 MB)
17/11/20 00:43:22 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:60738 (size: 24.3 KB, free: 338.3 MB)
17/11/20 00:43:22 INFO SparkContext: Created broadcast 66 from sql at <unknown>:0
17/11/20 00:43:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/11/20 00:43:23 INFO SparkContext: Starting job: sql at <unknown>:0
17/11/20 00:43:23 INFO DAGScheduler: Registering RDD 246 (sql at <unknown>:0)
17/11/20 00:43:23 INFO DAGScheduler: Got job 41 (sql at <unknown>:0) with 1 output partitions
17/11/20 00:43:23 INFO DAGScheduler: Final stage: ResultStage 60 (sql at <unknown>:0)
17/11/20 00:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
17/11/20 00:43:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
17/11/20 00:43:23 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[246] at sql at <unknown>:0), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 19.4 KB, free 335.9 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 8.2 KB, free 335.9 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:60738 (size: 8.2 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[246] at sql at <unknown>:0)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 59.0 (TID 88)
17/11/20 00:43:23 INFO FileScanRDD: Reading File path: file:///private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc02d7ab78a.parquet/part-00000-b559237b-4a6b-4809-9731-6374785db620.snappy.parquet, range: 0-2350, partition values: [empty row]
17/11/20 00:43:23 INFO CodecPool: Got brand-new decompressor [.snappy]
17/11/20 00:43:23 INFO MemoryStore: Block rdd_243_0 stored as values in memory (estimated size 5.6 KB, free 335.8 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added rdd_243_0 in memory on 127.0.0.1:60738 (size: 5.6 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 59.0 (TID 88). 3001 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 88) in 70 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ShuffleMapStage 59 (sql at <unknown>:0) finished in 0.070 s
17/11/20 00:43:23 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:43:23 INFO DAGScheduler: running: Set()
17/11/20 00:43:23 INFO DAGScheduler: waiting: Set(ResultStage 60)
17/11/20 00:43:23 INFO DAGScheduler: failed: Set()
17/11/20 00:43:23 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[249] at sql at <unknown>:0), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 7.0 KB, free 335.8 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.7 KB, free 335.8 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.2 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[249] at sql at <unknown>:0)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 89, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 60.0 (TID 89)
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 60.0 (TID 89). 2042 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 89) in 3 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ResultStage 60 (sql at <unknown>:0) finished in 0.004 s
17/11/20 00:43:23 INFO DAGScheduler: Job 41 finished: sql at <unknown>:0, took 0.088213 s
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_parquet`
17/11/20 00:43:23 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 00:43:23 INFO DAGScheduler: Registering RDD 253 (collect at utils.scala:210)
17/11/20 00:43:23 INFO DAGScheduler: Got job 42 (collect at utils.scala:210) with 1 output partitions
17/11/20 00:43:23 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:210)
17/11/20 00:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
17/11/20 00:43:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
17/11/20 00:43:23 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[253] at collect at utils.scala:210), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 19.4 KB, free 335.8 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 8.3 KB, free 335.8 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:60738 (size: 8.3 KB, free: 338.2 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[253] at collect at utils.scala:210)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 61.0 (TID 90)
17/11/20 00:43:23 INFO BlockManager: Found block rdd_243_0 locally
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 61.0 (TID 90). 2279 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 90) in 9 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ShuffleMapStage 61 (collect at utils.scala:210) finished in 0.010 s
17/11/20 00:43:23 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:43:23 INFO DAGScheduler: running: Set()
17/11/20 00:43:23 INFO DAGScheduler: waiting: Set(ResultStage 62)
17/11/20 00:43:23 INFO DAGScheduler: failed: Set()
17/11/20 00:43:23 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[256] at collect at utils.scala:210), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 7.0 KB, free 335.8 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 3.7 KB, free 335.8 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.2 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[256] at collect at utils.scala:210)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 91, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 62.0 (TID 91)
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 62.0 (TID 91). 2042 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 91) in 5 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:210) finished in 0.005 s
17/11/20 00:43:23 INFO DAGScheduler: Job 42 finished: collect at utils.scala:210, took 0.026354 s
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_parquet` AS `zzz12`
WHERE (0 = 1)
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
17/11/20 00:43:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:60738 in memory (size: 23.1 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:60738 in memory (size: 2.2 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3477
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3479
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3482
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3485
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3488
17/11/20 00:43:23 INFO ContextCleaner: Cleaned shuffle 16
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3745
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3847
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3850
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:60738 in memory (size: 5.3 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3478
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3480
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3483
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3486
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3489
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3586
17/11/20 00:43:23 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO DAGScheduler: Got job 43 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:43:23 INFO DAGScheduler: Final stage: ResultStage 63 (json at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:23 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:23 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:23 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[257] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:60738 in memory (size: 34.6 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3848
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3851
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3854
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3857
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:60738 in memory (size: 23.1 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:60738 in memory (size: 2.2 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3481
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3484
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3487
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:60738 in memory (size: 10.1 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3744
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:60738 in memory (size: 25.3 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3846
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3852
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3855
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3858
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3955
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:60738 in memory (size: 10.1 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3695
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:60738 in memory (size: 4.6 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3849
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3853
17/11/20 00:43:23 INFO ContextCleaner: Cleaned accumulator 3856
17/11/20 00:43:23 INFO ContextCleaner: Cleaned shuffle 18
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:60738 in memory (size: 8.2 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:60738 in memory (size: 8.3 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 87.8 KB, free 336.6 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 34.5 KB, free 336.6 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:60738 (size: 34.5 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[257] at json at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 6703 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 63.0 (TID 92)
17/11/20 00:43:23 INFO BlockManager: Found block rdd_11_0 locally
17/11/20 00:43:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/11/20 00:43:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
17/11/20 00:43:23 INFO FileOutputCommitter: Saved output of task 'attempt_20171120004323_0063_m_000000_0' to file:/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc053a7dc59.json/_temporary/0/task_20171120004323_0063_m_000000
17/11/20 00:43:23 INFO SparkHadoopMapRedUtil: attempt_20171120004323_0063_m_000000_0: Committed
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 63.0 (TID 92). 1758 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 92) in 51 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ResultStage 63 (json at NativeMethodAccessorImpl.java:0) finished in 0.052 s
17/11/20 00:43:23 INFO DAGScheduler: Job 43 finished: json at NativeMethodAccessorImpl.java:0, took 0.074233 s
17/11/20 00:43:23 INFO FileFormatWriter: Job null committed.
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:23 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 00:43:23 INFO DAGScheduler: Got job 44 (collect at utils.scala:58) with 1 output partitions
17/11/20 00:43:23 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:58)
17/11/20 00:43:23 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:23 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:23 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[264] at map at utils.scala:55), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 8.7 KB, free 336.6 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.6 KB, free 336.6 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:60738 (size: 4.6 KB, free: 338.4 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[264] at map at utils.scala:55)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 6992 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 64.0 (TID 93)
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 64.0 (TID 93). 1439 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 93) in 8 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:58) finished in 0.008 s
17/11/20 00:43:23 INFO DAGScheduler: Job 44 finished: collect at utils.scala:58, took 0.013063 s
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 284.0 KB, free 336.3 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 23.9 KB, free 336.3 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:60738 (size: 23.9 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 73 from json at NativeMethodAccessorImpl.java:0
17/11/20 00:43:23 INFO FileInputFormat: Total input paths to process : 1
17/11/20 00:43:23 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
17/11/20 00:43:23 INFO DAGScheduler: Got job 45 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
17/11/20 00:43:23 INFO DAGScheduler: Final stage: ResultStage 65 (json at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:23 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:23 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:23 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[267] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 7.4 KB, free 336.3 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 5.0 KB, free 336.3 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:60738 (size: 5.0 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 65 (MapPartitionsRDD[267] at json at NativeMethodAccessorImpl.java:0)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 6156 bytes)
17/11/20 00:43:23 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 95, localhost, executor driver, partition 1, PROCESS_LOCAL, 6156 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 65.0 (TID 94)
17/11/20 00:43:23 INFO Executor: Running task 1.0 in stage 65.0 (TID 95)
17/11/20 00:43:23 INFO HadoopRDD: Input split: file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc053a7dc59.json/part-00000-8d3faea0-036b-4954-aa8d-d359816c18a5.json:0+7300
17/11/20 00:43:23 INFO HadoopRDD: Input split: file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc053a7dc59.json/part-00000-8d3faea0-036b-4954-aa8d-d359816c18a5.json:7300+7300
17/11/20 00:43:23 INFO Executor: Finished task 1.0 in stage 65.0 (TID 95). 1953 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 95) in 15 ms on localhost (executor driver) (1/2)
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 65.0 (TID 94). 1953 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 94) in 18 ms on localhost (executor driver) (2/2)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ResultStage 65 (json at NativeMethodAccessorImpl.java:0) finished in 0.019 s
17/11/20 00:43:23 INFO DAGScheduler: Job 45 finished: json at NativeMethodAccessorImpl.java:0, took 0.023052 s
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: iris_json
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_json`
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: `iris_json`
17/11/20 00:43:23 INFO FileSourceStrategy: Pruning directories with: 
17/11/20 00:43:23 INFO FileSourceStrategy: Post-Scan Filters: 
17/11/20 00:43:23 INFO FileSourceStrategy: Output Data Schema: struct<Petal_Length: double, Petal_Width: double, Sepal_Length: double, Sepal_Width: double, Species: string ... 3 more fields>
17/11/20 00:43:23 INFO FileSourceStrategy: Pushed Filters: 
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 281.0 KB, free 336.0 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 23.7 KB, free 336.0 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:60738 (size: 23.7 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 75 from sql at <unknown>:0
17/11/20 00:43:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/11/20 00:43:23 INFO SparkContext: Starting job: sql at <unknown>:0
17/11/20 00:43:23 INFO DAGScheduler: Registering RDD 275 (sql at <unknown>:0)
17/11/20 00:43:23 INFO DAGScheduler: Got job 46 (sql at <unknown>:0) with 1 output partitions
17/11/20 00:43:23 INFO DAGScheduler: Final stage: ResultStage 67 (sql at <unknown>:0)
17/11/20 00:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
17/11/20 00:43:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
17/11/20 00:43:23 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[275] at sql at <unknown>:0), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 19.7 KB, free 336.0 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 10.0 KB, free 335.9 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:60738 (size: 10.0 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[275] at sql at <unknown>:0)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 6691 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 66.0 (TID 96)
17/11/20 00:43:23 INFO FileScanRDD: Reading File path: file:///private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc053a7dc59.json/part-00000-8d3faea0-036b-4954-aa8d-d359816c18a5.json, range: 0-14600, partition values: [empty row]
17/11/20 00:43:23 INFO MemoryStore: Block rdd_272_0 stored as values in memory (estimated size 5.6 KB, free 335.9 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added rdd_272_0 in memory on 127.0.0.1:60738 (size: 5.6 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 66.0 (TID 96). 2910 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 96) in 31 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ShuffleMapStage 66 (sql at <unknown>:0) finished in 0.031 s
17/11/20 00:43:23 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:43:23 INFO DAGScheduler: running: Set()
17/11/20 00:43:23 INFO DAGScheduler: waiting: Set(ResultStage 67)
17/11/20 00:43:23 INFO DAGScheduler: failed: Set()
17/11/20 00:43:23 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[278] at sql at <unknown>:0), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 7.0 KB, free 335.9 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 3.7 KB, free 335.9 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[278] at sql at <unknown>:0)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 97, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 67.0 (TID 97)
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 67.0 (TID 97). 2042 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 97) in 5 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ResultStage 67 (sql at <unknown>:0) finished in 0.005 s
17/11/20 00:43:23 INFO DAGScheduler: Job 46 finished: sql at <unknown>:0, took 0.044743 s
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_json`
17/11/20 00:43:23 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 00:43:23 INFO DAGScheduler: Registering RDD 282 (collect at utils.scala:210)
17/11/20 00:43:23 INFO DAGScheduler: Got job 47 (collect at utils.scala:210) with 1 output partitions
17/11/20 00:43:23 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:210)
17/11/20 00:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
17/11/20 00:43:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
17/11/20 00:43:23 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[282] at collect at utils.scala:210), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 19.7 KB, free 335.9 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 10.0 KB, free 335.9 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:60738 (size: 10.0 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[282] at collect at utils.scala:210)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 6683 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 68.0 (TID 98)
17/11/20 00:43:23 INFO BlockManager: Found block rdd_272_0 locally
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 68.0 (TID 98). 2188 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 98) in 6 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ShuffleMapStage 68 (collect at utils.scala:210) finished in 0.007 s
17/11/20 00:43:23 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:43:23 INFO DAGScheduler: running: Set()
17/11/20 00:43:23 INFO DAGScheduler: waiting: Set(ResultStage 69)
17/11/20 00:43:23 INFO DAGScheduler: failed: Set()
17/11/20 00:43:23 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[285] at collect at utils.scala:210), which has no missing parents
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 7.0 KB, free 335.9 MB)
17/11/20 00:43:23 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.7 KB, free 335.9 MB)
17/11/20 00:43:23 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.3 MB)
17/11/20 00:43:23 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[285] at collect at utils.scala:210)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
17/11/20 00:43:23 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 99, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/11/20 00:43:23 INFO Executor: Running task 0.0 in stage 69.0 (TID 99)
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:43:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:43:23 INFO Executor: Finished task 0.0 in stage 69.0 (TID 99). 2042 bytes result sent to driver
17/11/20 00:43:23 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 99) in 6 ms on localhost (executor driver) (1/1)
17/11/20 00:43:23 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
17/11/20 00:43:23 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:210) finished in 0.008 s
17/11/20 00:43:23 INFO DAGScheduler: Job 47 finished: collect at utils.scala:210, took 0.024042 s
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_json` AS `zzz13`
WHERE (0 = 1)
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:23 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:23 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:24 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:43:24 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 00:43:24 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:24 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:24 INFO HiveMetaStore: 0: get_database: default
17/11/20 00:43:24 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 00:43:24 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 00:43:24 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 00:43:24 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 00:43:24 INFO DAGScheduler: Got job 48 (collect at utils.scala:58) with 1 output partitions
17/11/20 00:43:24 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:58)
17/11/20 00:43:24 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:43:24 INFO DAGScheduler: Missing parents: List()
17/11/20 00:43:24 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[293] at map at utils.scala:55), which has no missing parents
17/11/20 00:43:24 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 8.7 KB, free 335.9 MB)
17/11/20 00:43:24 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 4.6 KB, free 335.9 MB)
17/11/20 00:43:24 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:60738 (size: 4.6 KB, free: 338.3 MB)
17/11/20 00:43:24 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:996
17/11/20 00:43:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[293] at map at utils.scala:55)
17/11/20 00:43:24 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
17/11/20 00:43:24 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 7048 bytes)
17/11/20 00:43:24 INFO Executor: Running task 0.0 in stage 70.0 (TID 100)
17/11/20 00:43:24 INFO Executor: Finished task 0.0 in stage 70.0 (TID 100). 1451 bytes result sent to driver
17/11/20 00:43:24 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 100) in 6 ms on localhost (executor driver) (1/1)
17/11/20 00:43:24 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
17/11/20 00:43:24 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:58) finished in 0.006 s
17/11/20 00:43:24 INFO DAGScheduler: Job 48 finished: collect at utils.scala:58, took 0.009741 s
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4113
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:60738 in memory (size: 4.6 KB, free: 338.3 MB)
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:60738 in memory (size: 5.0 KB, free: 338.3 MB)
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4241
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4243
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4246
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4251
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.3 MB)
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4458
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4240
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4245
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4248
17/11/20 00:44:23 INFO ContextCleaner: Cleaned shuffle 20
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:60738 in memory (size: 10.0 KB, free: 338.3 MB)
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4348
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:60738 in memory (size: 10.0 KB, free: 338.3 MB)
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4457
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:60738 in memory (size: 34.5 KB, free: 338.3 MB)
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4239
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4242
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4247
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4250
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:60738 in memory (size: 4.6 KB, free: 338.3 MB)
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4064
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4114
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:60738 in memory (size: 23.9 KB, free: 338.4 MB)
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4244
17/11/20 00:44:23 INFO ContextCleaner: Cleaned accumulator 4249
17/11/20 00:44:23 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:60738 in memory (size: 3.7 KB, free: 338.4 MB)
17/11/20 00:50:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:50:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
17/11/20 00:50:42 INFO SparkContext: Starting job: take at NativeMethodAccessorImpl.java:0
17/11/20 00:50:42 INFO DAGScheduler: Got job 49 (take at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:50:42 INFO DAGScheduler: Final stage: ResultStage 71 (take at NativeMethodAccessorImpl.java:0)
17/11/20 00:50:42 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:50:42 INFO DAGScheduler: Missing parents: List()
17/11/20 00:50:42 INFO DAGScheduler: Submitting ResultStage 71 (WorkerRDD[297] at RDD at rdd.scala:19), which has no missing parents
17/11/20 00:50:42 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 19.2 KB, free 336.4 MB)
17/11/20 00:50:42 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 10.1 KB, free 336.4 MB)
17/11/20 00:50:42 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:60738 (size: 10.1 KB, free: 338.4 MB)
17/11/20 00:50:42 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:996
17/11/20 00:50:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (WorkerRDD[297] at RDD at rdd.scala:19)
17/11/20 00:50:42 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
17/11/20 00:50:42 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 6662 bytes)
17/11/20 00:50:42 INFO Executor: Running task 0.0 in stage 71.0 (TID 101)
17/11/20 00:50:42 INFO BlockManager: Found block rdd_11_0 locally
17/11/20 00:50:43 INFO MemoryStore: Block rdd_297_0 stored as values in memory (estimated size 21.7 KB, free 336.4 MB)
17/11/20 00:50:43 INFO BlockManagerInfo: Added rdd_297_0 in memory on 127.0.0.1:60738 (size: 21.7 KB, free: 338.3 MB)
17/11/20 00:50:43 WARN Executor: 1 block locks were not released by TID = 101:
[rdd_297_0]
17/11/20 00:50:43 INFO Executor: Finished task 0.0 in stage 71.0 (TID 101). 3253 bytes result sent to driver
17/11/20 00:50:43 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 101) in 808 ms on localhost (executor driver) (1/1)
17/11/20 00:50:43 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
17/11/20 00:50:43 INFO DAGScheduler: ResultStage 71 (take at NativeMethodAccessorImpl.java:0) finished in 0.810 s
17/11/20 00:50:43 INFO DAGScheduler: Job 49 finished: take at NativeMethodAccessorImpl.java:0, took 0.828105 s
17/11/20 00:50:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:50:43 INFO SparkSqlParser: Parsing command: sparklyr_tmp_12dc0317381f7
17/11/20 00:50:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:50:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc0317381f7` AS `zzz14`
WHERE (0 = 1)
17/11/20 00:50:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:50:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc0317381f7`
LIMIT 10
17/11/20 00:50:43 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 00:50:43 INFO DAGScheduler: Got job 50 (collect at utils.scala:210) with 1 output partitions
17/11/20 00:50:43 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:210)
17/11/20 00:50:43 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:50:43 INFO DAGScheduler: Missing parents: List()
17/11/20 00:50:43 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[301] at collect at utils.scala:210), which has no missing parents
17/11/20 00:50:43 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 23.3 KB, free 336.3 MB)
17/11/20 00:50:43 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 11.8 KB, free 336.3 MB)
17/11/20 00:50:43 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:60738 (size: 11.8 KB, free: 338.3 MB)
17/11/20 00:50:43 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:996
17/11/20 00:50:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[301] at collect at utils.scala:210)
17/11/20 00:50:43 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
17/11/20 00:50:43 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 6609 bytes)
17/11/20 00:50:43 INFO Executor: Running task 0.0 in stage 72.0 (TID 102)
17/11/20 00:50:43 INFO BlockManager: Found block rdd_297_0 locally
17/11/20 00:50:43 INFO CodeGenerator: Code generated in 14.1486 ms
17/11/20 00:50:43 INFO CodeGenerator: Code generated in 21.673393 ms
17/11/20 00:50:43 WARN Executor: 1 block locks were not released by TID = 102:
[rdd_297_0]
17/11/20 00:50:43 INFO Executor: Finished task 0.0 in stage 72.0 (TID 102). 1820 bytes result sent to driver
17/11/20 00:50:43 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 102) in 50 ms on localhost (executor driver) (1/1)
17/11/20 00:50:43 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
17/11/20 00:50:43 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:210) finished in 0.051 s
17/11/20 00:50:43 INFO DAGScheduler: Job 50 finished: collect at utils.scala:210, took 0.061342 s
17/11/20 00:50:43 INFO CodeGenerator: Code generated in 10.108314 ms
17/11/20 00:51:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:51:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
17/11/20 00:51:00 INFO SparkContext: Starting job: take at NativeMethodAccessorImpl.java:0
17/11/20 00:51:00 INFO DAGScheduler: Registering RDD 305 (groupBy at applyutils.scala:9)
17/11/20 00:51:00 INFO DAGScheduler: Got job 51 (take at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:51:00 INFO DAGScheduler: Final stage: ResultStage 74 (take at NativeMethodAccessorImpl.java:0)
17/11/20 00:51:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
17/11/20 00:51:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)
17/11/20 00:51:00 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[305] at groupBy at applyutils.scala:9), which has no missing parents
17/11/20 00:51:00 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 19.5 KB, free 336.3 MB)
17/11/20 00:51:00 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 10.0 KB, free 336.3 MB)
17/11/20 00:51:00 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:60738 (size: 10.0 KB, free: 338.3 MB)
17/11/20 00:51:00 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:996
17/11/20 00:51:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[305] at groupBy at applyutils.scala:9)
17/11/20 00:51:00 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
17/11/20 00:51:00 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 6651 bytes)
17/11/20 00:51:00 INFO Executor: Running task 0.0 in stage 73.0 (TID 103)
17/11/20 00:51:00 INFO BlockManager: Found block rdd_11_0 locally
17/11/20 00:51:00 INFO Executor: Finished task 0.0 in stage 73.0 (TID 103). 1847 bytes result sent to driver
17/11/20 00:51:00 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 103) in 14 ms on localhost (executor driver) (1/1)
17/11/20 00:51:00 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
17/11/20 00:51:00 INFO DAGScheduler: ShuffleMapStage 73 (groupBy at applyutils.scala:9) finished in 0.014 s
17/11/20 00:51:00 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:51:00 INFO DAGScheduler: running: Set()
17/11/20 00:51:00 INFO DAGScheduler: waiting: Set(ResultStage 74)
17/11/20 00:51:00 INFO DAGScheduler: failed: Set()
17/11/20 00:51:00 INFO DAGScheduler: Submitting ResultStage 74 (WorkerRDD[308] at RDD at rdd.scala:19), which has no missing parents
17/11/20 00:51:00 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 21.9 KB, free 336.3 MB)
17/11/20 00:51:00 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 11.2 KB, free 336.3 MB)
17/11/20 00:51:00 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:60738 (size: 11.2 KB, free: 338.3 MB)
17/11/20 00:51:00 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:996
17/11/20 00:51:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (WorkerRDD[308] at RDD at rdd.scala:19)
17/11/20 00:51:00 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
17/11/20 00:51:00 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 104, localhost, executor driver, partition 0, ANY, 5809 bytes)
17/11/20 00:51:00 INFO Executor: Running task 0.0 in stage 74.0 (TID 104)
17/11/20 00:51:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 00:51:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:51:01 INFO MemoryStore: Block rdd_308_0 stored as values in memory (estimated size 1704.0 B, free 336.3 MB)
17/11/20 00:51:01 INFO BlockManagerInfo: Added rdd_308_0 in memory on 127.0.0.1:60738 (size: 1704.0 B, free: 338.3 MB)
17/11/20 00:51:01 INFO Executor: Finished task 0.0 in stage 74.0 (TID 104). 3670 bytes result sent to driver
17/11/20 00:51:01 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 104) in 1319 ms on localhost (executor driver) (1/1)
17/11/20 00:51:01 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
17/11/20 00:51:01 INFO DAGScheduler: ResultStage 74 (take at NativeMethodAccessorImpl.java:0) finished in 1.320 s
17/11/20 00:51:01 INFO DAGScheduler: Job 51 finished: take at NativeMethodAccessorImpl.java:0, took 1.356369 s
17/11/20 00:51:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:51:01 INFO SparkSqlParser: Parsing command: sparklyr_tmp_12dc01659987e
17/11/20 00:51:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:51:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc01659987e` AS `zzz15`
WHERE (0 = 1)
17/11/20 00:51:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:51:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_12dc01659987e`
LIMIT 10
17/11/20 00:51:02 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 00:51:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 143 bytes
17/11/20 00:51:02 INFO DAGScheduler: Got job 52 (collect at utils.scala:210) with 1 output partitions
17/11/20 00:51:02 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:210)
17/11/20 00:51:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
17/11/20 00:51:02 INFO DAGScheduler: Missing parents: List()
17/11/20 00:51:02 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[312] at collect at utils.scala:210), which has no missing parents
17/11/20 00:51:02 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 27.0 KB, free 336.2 MB)
17/11/20 00:51:02 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 13.3 KB, free 336.2 MB)
17/11/20 00:51:02 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:60738 (size: 13.3 KB, free: 338.3 MB)
17/11/20 00:51:02 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
17/11/20 00:51:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[312] at collect at utils.scala:210)
17/11/20 00:51:02 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
17/11/20 00:51:02 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5756 bytes)
17/11/20 00:51:02 INFO Executor: Running task 0.0 in stage 76.0 (TID 105)
17/11/20 00:51:02 INFO BlockManager: Found block rdd_308_0 locally
17/11/20 00:51:02 INFO CodeGenerator: Code generated in 6.982689 ms
17/11/20 00:51:02 INFO CodeGenerator: Code generated in 36.182404 ms
17/11/20 00:51:02 INFO Executor: Finished task 0.0 in stage 76.0 (TID 105). 1968 bytes result sent to driver
17/11/20 00:51:02 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 105) in 57 ms on localhost (executor driver) (1/1)
17/11/20 00:51:02 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
17/11/20 00:51:02 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:210) finished in 0.057 s
17/11/20 00:51:02 INFO DAGScheduler: Job 52 finished: collect at utils.scala:210, took 0.073928 s
17/11/20 00:51:02 INFO CodeGenerator: Code generated in 9.770554 ms
17/11/20 00:54:08 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 237.3 KB, free 336.0 MB)
17/11/20 00:54:08 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 23.1 KB, free 336.0 MB)
17/11/20 00:54:08 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:60738 (size: 23.1 KB, free: 338.3 MB)
17/11/20 00:54:08 INFO SparkContext: Created broadcast 86 from textFile at NativeMethodAccessorImpl.java:0
17/11/20 00:54:08 INFO FileInputFormat: Total input paths to process : 1
17/11/20 00:54:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/11/20 00:54:08 INFO DAGScheduler: Got job 53 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 00:54:08 INFO DAGScheduler: Final stage: ResultStage 77 (count at NativeMethodAccessorImpl.java:0)
17/11/20 00:54:08 INFO DAGScheduler: Parents of final stage: List()
17/11/20 00:54:08 INFO DAGScheduler: Missing parents: List()
17/11/20 00:54:08 INFO DAGScheduler: Submitting ResultStage 77 (/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T//RtmpYuxE25/file12dc0775c2f72.csv MapPartitionsRDD[314] at textFile at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 00:54:08 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 3.1 KB, free 336.0 MB)
17/11/20 00:54:08 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 1950.0 B, free 336.0 MB)
17/11/20 00:54:08 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:60738 (size: 1950.0 B, free: 338.3 MB)
17/11/20 00:54:08 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:996
17/11/20 00:54:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T//RtmpYuxE25/file12dc0775c2f72.csv MapPartitionsRDD[314] at textFile at NativeMethodAccessorImpl.java:0)
17/11/20 00:54:08 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
17/11/20 00:54:08 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 6010 bytes)
17/11/20 00:54:08 INFO Executor: Running task 0.0 in stage 77.0 (TID 106)
17/11/20 00:54:08 INFO HadoopRDD: Input split: file:/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/file12dc0775c2f72.csv:0+33313106
17/11/20 00:54:09 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:60738 in memory (size: 11.2 KB, free: 338.3 MB)
17/11/20 00:54:09 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:60738 in memory (size: 13.3 KB, free: 338.3 MB)
17/11/20 00:54:09 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:60738 in memory (size: 10.1 KB, free: 338.3 MB)
17/11/20 00:54:09 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:60738 in memory (size: 11.8 KB, free: 338.3 MB)
17/11/20 00:54:09 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:60738 in memory (size: 10.0 KB, free: 338.3 MB)
17/11/20 00:54:09 INFO Executor: Finished task 0.0 in stage 77.0 (TID 106). 1196 bytes result sent to driver
17/11/20 00:54:09 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 106) in 386 ms on localhost (executor driver) (1/1)
17/11/20 00:54:09 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
17/11/20 00:54:09 INFO DAGScheduler: ResultStage 77 (count at NativeMethodAccessorImpl.java:0) finished in 0.386 s
17/11/20 00:54:09 INFO DAGScheduler: Job 53 finished: count at NativeMethodAccessorImpl.java:0, took 0.396217 s
17/11/20 00:56:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:56:58 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
17/11/20 00:56:58 INFO SparkSqlParser: Parsing command: `batting`
17/11/20 00:56:58 WARN CacheManager: Asked to cache already cached data.
17/11/20 00:56:58 INFO SparkContext: Starting job: sql at <unknown>:0
17/11/20 00:56:58 INFO DAGScheduler: Registering RDD 317 (sql at <unknown>:0)
17/11/20 00:56:58 INFO DAGScheduler: Got job 54 (sql at <unknown>:0) with 1 output partitions
17/11/20 00:56:58 INFO DAGScheduler: Final stage: ResultStage 79 (sql at <unknown>:0)
17/11/20 00:56:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
17/11/20 00:56:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
17/11/20 00:56:58 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[317] at sql at <unknown>:0), which has no missing parents
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 29.7 KB, free 336.1 MB)
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 12.9 KB, free 336.1 MB)
17/11/20 00:56:58 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:60738 (size: 12.9 KB, free: 338.3 MB)
17/11/20 00:56:58 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:996
17/11/20 00:56:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[317] at sql at <unknown>:0)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks
17/11/20 00:56:58 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 6692 bytes)
17/11/20 00:56:58 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 108, localhost, executor driver, partition 1, PROCESS_LOCAL, 6692 bytes)
17/11/20 00:56:58 INFO Executor: Running task 0.0 in stage 78.0 (TID 107)
17/11/20 00:56:58 INFO Executor: Running task 1.0 in stage 78.0 (TID 108)
17/11/20 00:56:58 INFO BlockManager: Found block rdd_63_1 locally
17/11/20 00:56:58 INFO BlockManager: Found block rdd_63_0 locally
17/11/20 00:56:58 INFO Executor: Finished task 0.0 in stage 78.0 (TID 107). 2188 bytes result sent to driver
17/11/20 00:56:58 INFO Executor: Finished task 1.0 in stage 78.0 (TID 108). 2188 bytes result sent to driver
17/11/20 00:56:58 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 107) in 12 ms on localhost (executor driver) (1/2)
17/11/20 00:56:58 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 108) in 11 ms on localhost (executor driver) (2/2)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
17/11/20 00:56:58 INFO DAGScheduler: ShuffleMapStage 78 (sql at <unknown>:0) finished in 0.012 s
17/11/20 00:56:58 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:56:58 INFO DAGScheduler: running: Set()
17/11/20 00:56:58 INFO DAGScheduler: waiting: Set(ResultStage 79)
17/11/20 00:56:58 INFO DAGScheduler: failed: Set()
17/11/20 00:56:58 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[320] at sql at <unknown>:0), which has no missing parents
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 7.0 KB, free 336.1 MB)
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 3.7 KB, free 336.1 MB)
17/11/20 00:56:58 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.3 MB)
17/11/20 00:56:58 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
17/11/20 00:56:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[320] at sql at <unknown>:0)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
17/11/20 00:56:58 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 109, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/11/20 00:56:58 INFO Executor: Running task 0.0 in stage 79.0 (TID 109)
17/11/20 00:56:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/11/20 00:56:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/11/20 00:56:58 INFO Executor: Finished task 0.0 in stage 79.0 (TID 109). 2042 bytes result sent to driver
17/11/20 00:56:58 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 109) in 9 ms on localhost (executor driver) (1/1)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
17/11/20 00:56:58 INFO DAGScheduler: ResultStage 79 (sql at <unknown>:0) finished in 0.010 s
17/11/20 00:56:58 INFO DAGScheduler: Job 54 finished: sql at <unknown>:0, took 0.037441 s
17/11/20 00:56:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:56:58 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
17/11/20 00:56:58 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 00:56:58 INFO DAGScheduler: Registering RDD 324 (collect at utils.scala:210)
17/11/20 00:56:58 INFO DAGScheduler: Got job 55 (collect at utils.scala:210) with 1 output partitions
17/11/20 00:56:58 INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:210)
17/11/20 00:56:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
17/11/20 00:56:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 80)
17/11/20 00:56:58 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[324] at collect at utils.scala:210), which has no missing parents
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 29.7 KB, free 336.1 MB)
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 12.9 KB, free 336.0 MB)
17/11/20 00:56:58 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:60738 (size: 12.9 KB, free: 338.3 MB)
17/11/20 00:56:58 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:996
17/11/20 00:56:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[324] at collect at utils.scala:210)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks
17/11/20 00:56:58 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 6684 bytes)
17/11/20 00:56:58 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 111, localhost, executor driver, partition 1, PROCESS_LOCAL, 6684 bytes)
17/11/20 00:56:58 INFO Executor: Running task 0.0 in stage 80.0 (TID 110)
17/11/20 00:56:58 INFO Executor: Running task 1.0 in stage 80.0 (TID 111)
17/11/20 00:56:58 INFO BlockManager: Found block rdd_63_0 locally
17/11/20 00:56:58 INFO BlockManager: Found block rdd_63_1 locally
17/11/20 00:56:58 INFO Executor: Finished task 0.0 in stage 80.0 (TID 110). 2188 bytes result sent to driver
17/11/20 00:56:58 INFO Executor: Finished task 1.0 in stage 80.0 (TID 111). 2188 bytes result sent to driver
17/11/20 00:56:58 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 110) in 9 ms on localhost (executor driver) (1/2)
17/11/20 00:56:58 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 111) in 9 ms on localhost (executor driver) (2/2)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
17/11/20 00:56:58 INFO DAGScheduler: ShuffleMapStage 80 (collect at utils.scala:210) finished in 0.010 s
17/11/20 00:56:58 INFO DAGScheduler: looking for newly runnable stages
17/11/20 00:56:58 INFO DAGScheduler: running: Set()
17/11/20 00:56:58 INFO DAGScheduler: waiting: Set(ResultStage 81)
17/11/20 00:56:58 INFO DAGScheduler: failed: Set()
17/11/20 00:56:58 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[327] at collect at utils.scala:210), which has no missing parents
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 7.0 KB, free 336.0 MB)
17/11/20 00:56:58 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 3.7 KB, free 336.0 MB)
17/11/20 00:56:58 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:60738 (size: 3.7 KB, free: 338.3 MB)
17/11/20 00:56:58 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
17/11/20 00:56:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[327] at collect at utils.scala:210)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
17/11/20 00:56:58 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 112, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/11/20 00:56:58 INFO Executor: Running task 0.0 in stage 81.0 (TID 112)
17/11/20 00:56:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/11/20 00:56:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 00:56:58 INFO Executor: Finished task 0.0 in stage 81.0 (TID 112). 1955 bytes result sent to driver
17/11/20 00:56:58 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 112) in 3 ms on localhost (executor driver) (1/1)
17/11/20 00:56:58 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
17/11/20 00:56:58 INFO DAGScheduler: ResultStage 81 (collect at utils.scala:210) finished in 0.004 s
17/11/20 00:56:58 INFO DAGScheduler: Job 55 finished: collect at utils.scala:210, took 0.023494 s
17/11/20 00:57:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 00:57:26 INFO SparkSqlParser: Parsing command: UNCACHE TABLE `batting`
17/11/20 00:57:26 INFO SparkSqlParser: Parsing command: `batting`
17/11/20 00:57:26 INFO MapPartitionsRDD: Removing RDD 63 from persistence list
17/11/20 00:57:26 INFO BlockManager: Removing RDD 63
17/11/20 00:59:30 INFO SparkContext: Invoking stop() from shutdown hook
17/11/20 00:59:30 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/11/20 00:59:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/11/20 00:59:30 INFO MemoryStore: MemoryStore cleared
17/11/20 00:59:30 INFO BlockManager: BlockManager stopped
17/11/20 00:59:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/11/20 00:59:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/11/20 00:59:30 INFO SparkContext: Successfully stopped SparkContext
17/11/20 00:59:30 INFO ShutdownHookManager: Shutdown hook called
17/11/20 00:59:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-e4efcad8-f561-46e7-a432-fe2d07a43141
17/11/20 01:00:59 INFO SparkContext: Running Spark version 2.1.0
17/11/20 01:00:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/11/20 01:00:59 INFO SecurityManager: Changing view acls to: Macbook
17/11/20 01:00:59 INFO SecurityManager: Changing modify acls to: Macbook
17/11/20 01:00:59 INFO SecurityManager: Changing view acls groups to: 
17/11/20 01:00:59 INFO SecurityManager: Changing modify acls groups to: 
17/11/20 01:00:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Macbook); groups with view permissions: Set(); users  with modify permissions: Set(Macbook); groups with modify permissions: Set()
17/11/20 01:00:59 INFO Utils: Successfully started service 'sparkDriver' on port 63637.
17/11/20 01:00:59 INFO SparkEnv: Registering MapOutputTracker
17/11/20 01:00:59 INFO SparkEnv: Registering BlockManagerMaster
17/11/20 01:00:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/11/20 01:00:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/11/20 01:00:59 INFO DiskBlockManager: Created local directory at /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/blockmgr-e47c5241-3cb4-47c0-95bc-bf929f77a8b1
17/11/20 01:00:59 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/11/20 01:00:59 INFO SparkEnv: Registering OutputCommitCoordinator
17/11/20 01:01:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/11/20 01:01:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/11/20 01:01:00 INFO SparkContext: Added JAR file:/Users/Macbook/Library/R/3.4/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:63637/jars/sparklyr-2.1-2.11.jar with timestamp 1511139660113
17/11/20 01:01:00 INFO Executor: Starting executor ID driver on host localhost
17/11/20 01:01:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63638.
17/11/20 01:01:00 INFO NettyBlockTransferService: Server created on 127.0.0.1:63638
17/11/20 01:01:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/11/20 01:01:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63638, None)
17/11/20 01:01:00 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63638 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63638, None)
17/11/20 01:01:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63638, None)
17/11/20 01:01:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63638, None)
17/11/20 01:01:00 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/11/20 01:01:00 INFO SharedState: Warehouse path is 'file:/Users/Macbook/Documents/Study/study_R/spark-warehouse'.
17/11/20 01:01:00 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/11/20 01:01:01 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/11/20 01:01:01 INFO ObjectStore: ObjectStore, initialize called
17/11/20 01:01:01 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/11/20 01:01:01 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/11/20 01:01:03 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/11/20 01:01:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:05 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/11/20 01:01:05 INFO ObjectStore: Initialized ObjectStore
17/11/20 01:01:05 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/11/20 01:01:05 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/11/20 01:01:05 INFO HiveMetaStore: Added admin role in metastore
17/11/20 01:01:05 INFO HiveMetaStore: Added public role in metastore
17/11/20 01:01:05 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/11/20 01:01:05 INFO HiveMetaStore: 0: get_all_databases
17/11/20 01:01:05 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_all_databases	
17/11/20 01:01:05 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/11/20 01:01:05 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/11/20 01:01:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:06 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/5967b872-d3e8-46f7-bf6b-fb3420c89f04_resources
17/11/20 01:01:06 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/5967b872-d3e8-46f7-bf6b-fb3420c89f04
17/11/20 01:01:06 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/Macbook/5967b872-d3e8-46f7-bf6b-fb3420c89f04
17/11/20 01:01:06 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/5967b872-d3e8-46f7-bf6b-fb3420c89f04/_tmp_space.db
17/11/20 01:01:06 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/Macbook/Documents/Study/study_R/spark-warehouse
17/11/20 01:01:06 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:06 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:06 INFO HiveMetaStore: 0: get_database: global_temp
17/11/20 01:01:06 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/11/20 01:01:06 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/11/20 01:01:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:01:08 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:08 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:08 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:08 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:01:08 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:01:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:01:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:01:08 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:08 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:08 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:08 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:01:08 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:01:25 INFO SparkContext: Invoking stop() from shutdown hook
17/11/20 01:01:25 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/11/20 01:01:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/11/20 01:01:25 INFO MemoryStore: MemoryStore cleared
17/11/20 01:01:25 INFO BlockManager: BlockManager stopped
17/11/20 01:01:25 INFO BlockManagerMaster: BlockManagerMaster stopped
17/11/20 01:01:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/11/20 01:01:25 INFO SparkContext: Successfully stopped SparkContext
17/11/20 01:01:25 INFO ShutdownHookManager: Shutdown hook called
17/11/20 01:01:25 INFO ShutdownHookManager: Deleting directory /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-7563b4fe-fffe-4c86-82f8-e0e53bc15b8a
17/11/20 01:01:40 INFO SparkContext: Running Spark version 2.1.0
17/11/20 01:01:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/11/20 01:01:41 INFO SecurityManager: Changing view acls to: Macbook
17/11/20 01:01:41 INFO SecurityManager: Changing modify acls to: Macbook
17/11/20 01:01:41 INFO SecurityManager: Changing view acls groups to: 
17/11/20 01:01:41 INFO SecurityManager: Changing modify acls groups to: 
17/11/20 01:01:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Macbook); groups with view permissions: Set(); users  with modify permissions: Set(Macbook); groups with modify permissions: Set()
17/11/20 01:01:41 INFO Utils: Successfully started service 'sparkDriver' on port 63715.
17/11/20 01:01:41 INFO SparkEnv: Registering MapOutputTracker
17/11/20 01:01:41 INFO SparkEnv: Registering BlockManagerMaster
17/11/20 01:01:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/11/20 01:01:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/11/20 01:01:41 INFO DiskBlockManager: Created local directory at /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/blockmgr-1a1d2cc4-21ff-4128-86ec-f6d56c0b5f36
17/11/20 01:01:41 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/11/20 01:01:41 INFO SparkEnv: Registering OutputCommitCoordinator
17/11/20 01:01:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/11/20 01:01:41 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/11/20 01:01:41 INFO SparkContext: Added JAR file:/Users/Macbook/Library/R/3.4/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:63715/jars/sparklyr-2.1-2.11.jar with timestamp 1511139701911
17/11/20 01:01:42 INFO Executor: Starting executor ID driver on host localhost
17/11/20 01:01:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63716.
17/11/20 01:01:42 INFO NettyBlockTransferService: Server created on 127.0.0.1:63716
17/11/20 01:01:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/11/20 01:01:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63716, None)
17/11/20 01:01:42 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63716 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63716, None)
17/11/20 01:01:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63716, None)
17/11/20 01:01:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63716, None)
17/11/20 01:01:42 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/11/20 01:01:42 INFO SharedState: Warehouse path is 'file:/Users/Macbook/Documents/Study/study_R/spark-warehouse'.
17/11/20 01:01:42 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/11/20 01:01:43 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/11/20 01:01:43 INFO ObjectStore: ObjectStore, initialize called
17/11/20 01:01:43 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/11/20 01:01:43 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/11/20 01:01:45 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/11/20 01:01:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:47 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/11/20 01:01:47 INFO ObjectStore: Initialized ObjectStore
17/11/20 01:01:47 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/11/20 01:01:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/11/20 01:01:47 INFO HiveMetaStore: Added admin role in metastore
17/11/20 01:01:47 INFO HiveMetaStore: Added public role in metastore
17/11/20 01:01:48 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/11/20 01:01:48 INFO HiveMetaStore: 0: get_all_databases
17/11/20 01:01:48 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_all_databases	
17/11/20 01:01:48 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/11/20 01:01:48 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/11/20 01:01:48 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:01:48 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/7baf2bc6-fb6b-4b8e-93bb-9ba6a881c640_resources
17/11/20 01:01:48 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/7baf2bc6-fb6b-4b8e-93bb-9ba6a881c640
17/11/20 01:01:48 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/Macbook/7baf2bc6-fb6b-4b8e-93bb-9ba6a881c640
17/11/20 01:01:48 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/7baf2bc6-fb6b-4b8e-93bb-9ba6a881c640/_tmp_space.db
17/11/20 01:01:48 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/Macbook/Documents/Study/study_R/spark-warehouse
17/11/20 01:01:48 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:48 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:48 INFO HiveMetaStore: 0: get_database: global_temp
17/11/20 01:01:48 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/11/20 01:01:48 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/11/20 01:01:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:01:50 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:50 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:01:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:01:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:01:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:01:50 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:50 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:01:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:01:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:01:50 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:01:50 INFO SparkContext: Invoking stop() from shutdown hook
17/11/20 01:01:50 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/11/20 01:01:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/11/20 01:01:50 INFO MemoryStore: MemoryStore cleared
17/11/20 01:01:50 INFO BlockManager: BlockManager stopped
17/11/20 01:01:50 INFO BlockManagerMaster: BlockManagerMaster stopped
17/11/20 01:01:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/11/20 01:01:50 INFO SparkContext: Successfully stopped SparkContext
17/11/20 01:01:50 INFO ShutdownHookManager: Shutdown hook called
17/11/20 01:01:50 INFO ShutdownHookManager: Deleting directory /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-dfc20c5b-dd2a-4f0d-962e-4caedb0bc51e
17/11/20 01:05:00 INFO SparkContext: Running Spark version 2.1.0
17/11/20 01:05:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/11/20 01:05:00 INFO SecurityManager: Changing view acls to: Macbook
17/11/20 01:05:00 INFO SecurityManager: Changing modify acls to: Macbook
17/11/20 01:05:00 INFO SecurityManager: Changing view acls groups to: 
17/11/20 01:05:00 INFO SecurityManager: Changing modify acls groups to: 
17/11/20 01:05:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Macbook); groups with view permissions: Set(); users  with modify permissions: Set(Macbook); groups with modify permissions: Set()
17/11/20 01:05:00 INFO Utils: Successfully started service 'sparkDriver' on port 64499.
17/11/20 01:05:00 INFO SparkEnv: Registering MapOutputTracker
17/11/20 01:05:00 INFO SparkEnv: Registering BlockManagerMaster
17/11/20 01:05:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/11/20 01:05:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/11/20 01:05:00 INFO DiskBlockManager: Created local directory at /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/blockmgr-4beaa924-66fa-4079-9566-a1da5c6a276d
17/11/20 01:05:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/11/20 01:05:00 INFO SparkEnv: Registering OutputCommitCoordinator
17/11/20 01:05:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/11/20 01:05:01 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.16.jar at spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-core_2.11-2.1.16.jar with timestamp 1511139901303
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.16.jar at spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-ml_2.11-2.1.16.jar with timestamp 1511139901304
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.16.jar at spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-repl_2.11-2.1.16.jar with timestamp 1511139901304
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:64499/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1511139901304
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-genmodel-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-genmodel-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-core-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-core-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-algos-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-algos-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-web-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-web-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-ext-xgboost-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-ext-xgboost-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-scala_2.11-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-persist-hdfs-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-persist-s3-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-persist-s3-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-automl-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-automl-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:64499/jars/org.joda_joda-convert-1.7.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:64499/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.google.code.gson_gson-2.6.2.jar at spark://127.0.0.1:64499/jars/com.google.code.gson_gson-2.6.2.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar at spark://127.0.0.1:64499/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.4.jar at spark://127.0.0.1:64499/jars/ai.h2o_deepwater-backend-api-1.0.4.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.slf4j_slf4j-log4j12-1.7.5.jar at spark://127.0.0.1:64499/jars/org.slf4j_slf4j-log4j12-1.7.5.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar at spark://127.0.0.1:64499/jars/org.slf4j_slf4j-api-1.7.5.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/log4j_log4j-1.2.17.jar at spark://127.0.0.1:64499/jars/log4j_log4j-1.2.17.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:64499/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:64499/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1511139901305
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:64499/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:64499/jars/commons-io_commons-io-2.4.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:64499/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:64499/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-jaas-pam-3.14.0.7.jar at spark://127.0.0.1:64499/jars/ai.h2o_h2o-jaas-pam-3.14.0.7.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:64499/jars/com.google.guava_guava-16.0.1.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:64499/jars/commons-lang_commons-lang-2.6.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.kohsuke_libpam4j-1.8.jar at spark://127.0.0.1:64499/jars/org.kohsuke_libpam4j-1.8.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/net.java.dev.jna_jna-4.0.0.jar at spark://127.0.0.1:64499/jars/net.java.dev.jna_jna-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:64499/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:64499/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.21.jar at spark://127.0.0.1:64499/jars/com.esotericsoftware.kryo_kryo-2.21.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar at spark://127.0.0.1:64499/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.esotericsoftware.minlog_minlog-1.2.jar at spark://127.0.0.1:64499/jars/com.esotericsoftware.minlog_minlog-1.2.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.objenesis_objenesis-1.2.jar at spark://127.0.0.1:64499/jars/org.objenesis_objenesis-1.2.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.ow2.asm_asm-4.0.jar at spark://127.0.0.1:64499/jars/org.ow2.asm_asm-4.0.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:64499/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:64499/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:64499/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1511139901308
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1511139901309
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1511139901309
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:64499/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1511139901309
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:64499/jars/joda-time_joda-time-2.8.1.jar with timestamp 1511139901309
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:64499/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1511139901309
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:64499/jars/commons-codec_commons-codec-1.6.jar with timestamp 1511139901309
17/11/20 01:05:01 INFO SparkContext: Added JAR file:/Users/Macbook/Library/R/3.4/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64499/jars/sparklyr-2.1-2.11.jar with timestamp 1511139901309
17/11/20 01:05:01 INFO Executor: Starting executor ID driver on host localhost
17/11/20 01:05:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64500.
17/11/20 01:05:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:64500
17/11/20 01:05:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/11/20 01:05:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64500, None)
17/11/20 01:05:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64500 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64500, None)
17/11/20 01:05:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64500, None)
17/11/20 01:05:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64500, None)
17/11/20 01:05:01 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/11/20 01:05:01 INFO SharedState: Warehouse path is 'file:/Users/Macbook/Documents/Study/study_R/spark-warehouse'.
17/11/20 01:05:02 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/11/20 01:05:02 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/11/20 01:05:02 INFO ObjectStore: ObjectStore, initialize called
17/11/20 01:05:03 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/11/20 01:05:03 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/11/20 01:05:04 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/11/20 01:05:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:05:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:05:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:05:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:05:06 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/11/20 01:05:06 INFO ObjectStore: Initialized ObjectStore
17/11/20 01:05:06 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/11/20 01:05:07 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/11/20 01:05:07 INFO HiveMetaStore: Added admin role in metastore
17/11/20 01:05:07 INFO HiveMetaStore: Added public role in metastore
17/11/20 01:05:07 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/11/20 01:05:07 INFO HiveMetaStore: 0: get_all_databases
17/11/20 01:05:07 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_all_databases	
17/11/20 01:05:07 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/11/20 01:05:07 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/11/20 01:05:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:05:07 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/4918a2a7-a6fd-442b-94df-a1d89e10a404_resources
17/11/20 01:05:07 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/4918a2a7-a6fd-442b-94df-a1d89e10a404
17/11/20 01:05:07 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/Macbook/4918a2a7-a6fd-442b-94df-a1d89e10a404
17/11/20 01:05:07 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/4918a2a7-a6fd-442b-94df-a1d89e10a404/_tmp_space.db
17/11/20 01:05:07 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/Macbook/Documents/Study/study_R/spark-warehouse
17/11/20 01:05:07 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:07 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:07 INFO HiveMetaStore: 0: get_database: global_temp
17/11/20 01:05:07 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/11/20 01:05:07 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/11/20 01:05:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:05:09 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:09 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:09 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:09 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:05:09 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:05:10 INFO CodeGenerator: Code generated in 180.235871 ms
17/11/20 01:05:10 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 01:05:10 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/11/20 01:05:10 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/11/20 01:05:10 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:05:10 INFO DAGScheduler: Missing parents: List()
17/11/20 01:05:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/11/20 01:05:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/11/20 01:05:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/11/20 01:05:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64500 (size: 4.6 KB, free: 366.3 MB)
17/11/20 01:05:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/11/20 01:05:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/11/20 01:05:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11596 bytes)
17/11/20 01:05:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/11/20 01:05:10 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:10 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64499 after 14 ms (0 ms spent in bootstraps)
17/11/20 01:05:10 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp3086342815638860281.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/commons-httpclient_commons-httpclient-3.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8022125617080258768.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1729830673753376781.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp4797939702391157974.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.google.code.gson_gson-2.6.2.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.google.code.gson_gson-2.6.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7271156915838188605.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.google.code.gson_gson-2.6.2.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/commons-codec_commons-codec-1.6.jar with timestamp 1511139901309
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/commons-codec_commons-codec-1.6.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp4241564008435681917.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/commons-codec_commons-codec-1.6.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.javassist_javassist-3.18.2-GA.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp6343352426660594794.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.javassist_javassist-3.18.2-GA.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp6917630212059363017.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp2205199511855524469.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1559194360926939873.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp4683066947185221958.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.ow2.asm_asm-4.0.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.ow2.asm_asm-4.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7420743993707733105.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.ow2.asm_asm-4.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-persist-hdfs-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-persist-hdfs-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1643015716223440122.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-persist-hdfs-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-jaas-pam-3.14.0.7.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-jaas-pam-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp2564009283860242610.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-jaas-pam-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp545472374000190520.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-queries-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5042295222744040067.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-core_2.11-2.1.16.jar with timestamp 1511139901303
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-core_2.11-2.1.16.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp6571830798216494675.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_sparkling-water-core_2.11-2.1.16.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.spatial4j_spatial4j-0.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp503533271271234667.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.spatial4j_spatial4j-0.3.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/log4j_log4j-1.2.17.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/log4j_log4j-1.2.17.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8241126133685491141.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/log4j_log4j-1.2.17.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-ext-xgboost-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-ext-xgboost-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5999759144508938748.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-ext-xgboost-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-scala_2.11-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-scala_2.11-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5873062699957995208.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-scala_2.11-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.apache.commons_commons-math3-3.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5088175890974982809.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.apache.commons_commons-math3-3.3.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp9021662126996857890.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.github.rwl_jtransforms-2.4.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp9173744914855702679.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8261216806355022978.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7320910573538394536.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-ml_2.11-2.1.16.jar with timestamp 1511139901304
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-ml_2.11-2.1.16.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp101006216843197342.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_sparkling-water-ml_2.11-2.1.16.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.kohsuke_libpam4j-1.8.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.kohsuke_libpam4j-1.8.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7072816485341973521.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.kohsuke_libpam4j-1.8.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.slf4j_slf4j-log4j12-1.7.5.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.slf4j_slf4j-log4j12-1.7.5.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp4427728663806858211.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.slf4j_slf4j-log4j12-1.7.5.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/commons-io_commons-io-2.4.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/commons-io_commons-io-2.4.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp2085343783911023860.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/commons-io_commons-io-2.4.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1925758550187271422.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1511139901309
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/commons-logging_commons-logging-1.1.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5736818697907243574.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/commons-logging_commons-logging-1.1.3.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-persist-s3-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-persist-s3-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5683160415722003377.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-persist-s3-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8888851000332154165.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1511139901304
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/no.priv.garshol.duke_duke-1.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp752040181772797064.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/no.priv.garshol.duke_duke-1.2.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_deepwater-backend-api-1.0.4.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_deepwater-backend-api-1.0.4.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1301248194425542255.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_deepwater-backend-api-1.0.4.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/commons-lang_commons-lang-2.6.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/commons-lang_commons-lang-2.6.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7263681947252431005.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/commons-lang_commons-lang-2.6.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-algos-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-algos-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp9108326978266622724.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-algos-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.esotericsoftware.kryo_kryo-2.21.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.esotericsoftware.kryo_kryo-2.21.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8930481137026502860.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.esotericsoftware.kryo_kryo-2.21.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7721570777301733231.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp2285785052229229988.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp3892927418347632358.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-repl_2.11-2.1.16.jar with timestamp 1511139901304
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_sparkling-water-repl_2.11-2.1.16.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp9071448876817335378.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_sparkling-water-repl_2.11-2.1.16.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-core-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp4663444757458632439.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp2976182754049900916.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1511139901309
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1844459310087997736.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1755255761481330911.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.esotericsoftware.reflectasm_reflectasm-1.07.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.google.guava_guava-16.0.1.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.google.guava_guava-16.0.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp3990283722483351561.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.google.guava_guava-16.0.1.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp6531241647240872948.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp6502841865230734820.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-genmodel-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-genmodel-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1300779744244922184.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-genmodel-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-web-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-web-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp6356015027250872535.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-web-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/net.java.dev.jna_jna-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/net.java.dev.jna_jna-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp2570391713687735383.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/net.java.dev.jna_jna-4.0.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/gov.nist.math_jama-1.0.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1590459392703662723.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/gov.nist.math_jama-1.0.3.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/sparklyr-2.1-2.11.jar with timestamp 1511139901309
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/sparklyr-2.1-2.11.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1525612802816958915.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/sparklyr-2.1-2.11.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.objenesis_objenesis-1.2.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.objenesis_objenesis-1.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7805956641293355412.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.objenesis_objenesis-1.2.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8518600833570575394.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8941620416985474773.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1511139901309
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp83235258648555537.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-core-3.14.0.7.jar with timestamp 1511139901304
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-core-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp6190219269061155215.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-core-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/net.sf.opencsv_opencsv-2.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5364769635328423560.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/net.sf.opencsv_opencsv-2.3.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1511139901306
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1893032828495492006.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1511139901309
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8633066924022790971.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/joda-time_joda-time-2.8.1.jar with timestamp 1511139901309
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/joda-time_joda-time-2.8.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp5490855554296945476.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/joda-time_joda-time-2.8.1.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8181132172030164772.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-automl-3.14.0.7.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/ai.h2o_h2o-automl-3.14.0.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp8074735622302575238.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/ai.h2o_h2o-automl-3.14.0.7.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.slf4j_slf4j-api-1.7.5.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.slf4j_slf4j-api-1.7.5.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp1110853545551712117.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.slf4j_slf4j-api-1.7.5.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.mapdb_mapdb-0.9.9.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp3739265796391984112.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.mapdb_mapdb-0.9.9.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/com.esotericsoftware.minlog_minlog-1.2.jar with timestamp 1511139901308
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/com.esotericsoftware.minlog_minlog-1.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp7711189480211339045.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/com.esotericsoftware.minlog_minlog-1.2.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1511139901307
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp201230433130703514.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/11/20 01:05:11 INFO Executor: Fetching spark://127.0.0.1:64499/jars/org.joda_joda-convert-1.7.jar with timestamp 1511139901305
17/11/20 01:05:11 INFO Utils: Fetching spark://127.0.0.1:64499/jars/org.joda_joda-convert-1.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/fetchFileTemp723326304538155337.tmp
17/11/20 01:05:11 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/userFiles-f958ea74-9ea9-4527-abc1-825a499d9587/org.joda_joda-convert-1.7.jar to class loader
17/11/20 01:05:12 INFO CodeGenerator: Code generated in 13.995353 ms
17/11/20 01:05:12 INFO CodeGenerator: Code generated in 15.506256 ms
17/11/20 01:05:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/11/20 01:05:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1266 ms on localhost (executor driver) (1/1)
17/11/20 01:05:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/11/20 01:05:12 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 1.291 s
17/11/20 01:05:12 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 1.460506 s
17/11/20 01:05:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:12 INFO SparkSqlParser: Parsing command: mtcars
17/11/20 01:05:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:12 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
17/11/20 01:05:12 INFO SparkSqlParser: Parsing command: `mtcars`
17/11/20 01:05:12 INFO FileSourceStrategy: Pruning directories with: 
17/11/20 01:05:12 INFO FileSourceStrategy: Post-Scan Filters: 
17/11/20 01:05:12 INFO FileSourceStrategy: Output Data Schema: struct<mpg: double, cyl: double, disp: double, hp: double, drat: double ... 9 more fields>
17/11/20 01:05:12 INFO FileSourceStrategy: Pushed Filters: 
17/11/20 01:05:12 INFO CodeGenerator: Code generated in 8.663526 ms
17/11/20 01:05:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 300.8 KB, free 366.0 MB)
17/11/20 01:05:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 366.0 MB)
17/11/20 01:05:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64500 (size: 25.4 KB, free: 366.3 MB)
17/11/20 01:05:12 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/11/20 01:05:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/11/20 01:05:12 INFO CodeGenerator: Code generated in 12.587575 ms
17/11/20 01:05:12 INFO CodeGenerator: Code generated in 10.658622 ms
17/11/20 01:05:12 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/11/20 01:05:12 INFO ContextCleaner: Cleaned accumulator 54
17/11/20 01:05:12 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:05:12 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 01:05:12 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:05:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/11/20 01:05:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/11/20 01:05:12 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 01:05:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.2 KB, free 365.9 MB)
17/11/20 01:05:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/11/20 01:05:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64500 (size: 11.0 KB, free: 366.3 MB)
17/11/20 01:05:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:05:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/11/20 01:05:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12245 bytes)
17/11/20 01:05:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/11/20 01:05:12 INFO FileScanRDD: Reading File path: file:///var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpYuxE25/spark_serialize_600df8759318fe0d3e7cd227dfb889264b9395236a2336b9c1d32f83ed509279.csv, range: 0-1303, partition values: [empty row]
17/11/20 01:05:13 INFO CodeGenerator: Code generated in 17.481197 ms
17/11/20 01:05:13 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 4.2 KB, free 365.9 MB)
17/11/20 01:05:13 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:64500 (size: 4.2 KB, free: 366.3 MB)
17/11/20 01:05:13 INFO CodeGenerator: Code generated in 5.277937 ms
17/11/20 01:05:13 INFO CodeGenerator: Code generated in 23.382979 ms
17/11/20 01:05:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2997 bytes result sent to driver
17/11/20 01:05:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 253 ms on localhost (executor driver) (1/1)
17/11/20 01:05:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/11/20 01:05:13 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.257 s
17/11/20 01:05:13 INFO DAGScheduler: looking for newly runnable stages
17/11/20 01:05:13 INFO DAGScheduler: running: Set()
17/11/20 01:05:13 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/11/20 01:05:13 INFO DAGScheduler: failed: Set()
17/11/20 01:05:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 01:05:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/11/20 01:05:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/11/20 01:05:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64500 (size: 3.7 KB, free: 366.3 MB)
17/11/20 01:05:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:05:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/11/20 01:05:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 11508 bytes)
17/11/20 01:05:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/11/20 01:05:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 01:05:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/11/20 01:05:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/11/20 01:05:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 38 ms on localhost (executor driver) (1/1)
17/11/20 01:05:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/11/20 01:05:13 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.039 s
17/11/20 01:05:13 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.371186 s
17/11/20 01:05:13 INFO CodeGenerator: Code generated in 9.624171 ms
17/11/20 01:05:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:13 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
17/11/20 01:05:13 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 01:05:13 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:210)
17/11/20 01:05:13 INFO DAGScheduler: Got job 2 (collect at utils.scala:210) with 1 output partitions
17/11/20 01:05:13 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:210)
17/11/20 01:05:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/11/20 01:05:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/11/20 01:05:13 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210), which has no missing parents
17/11/20 01:05:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 23.2 KB, free 365.9 MB)
17/11/20 01:05:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/11/20 01:05:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64500 (size: 11.0 KB, free: 366.2 MB)
17/11/20 01:05:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210)
17/11/20 01:05:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/11/20 01:05:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 12237 bytes)
17/11/20 01:05:13 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/11/20 01:05:13 INFO BlockManager: Found block rdd_9_0 locally
17/11/20 01:05:13 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2188 bytes result sent to driver
17/11/20 01:05:13 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (executor driver) (1/1)
17/11/20 01:05:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/11/20 01:05:13 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:210) finished in 0.020 s
17/11/20 01:05:13 INFO DAGScheduler: looking for newly runnable stages
17/11/20 01:05:13 INFO DAGScheduler: running: Set()
17/11/20 01:05:13 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/11/20 01:05:13 INFO DAGScheduler: failed: Set()
17/11/20 01:05:13 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210), which has no missing parents
17/11/20 01:05:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/11/20 01:05:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/11/20 01:05:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64500 (size: 3.7 KB, free: 366.2 MB)
17/11/20 01:05:13 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210)
17/11/20 01:05:13 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/11/20 01:05:13 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 11500 bytes)
17/11/20 01:05:13 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/11/20 01:05:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 01:05:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 01:05:13 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/11/20 01:05:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
17/11/20 01:05:13 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/11/20 01:05:13 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:210) finished in 0.011 s
17/11/20 01:05:13 INFO DAGScheduler: Job 2 finished: collect at utils.scala:210, took 0.055178 s
17/11/20 01:05:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz16`
WHERE (0 = 1)
17/11/20 01:05:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:05:13 INFO CodeGenerator: Code generated in 15.922675 ms
17/11/20 01:05:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:05:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:05:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:05:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:05:13 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64500 in memory (size: 11.0 KB, free: 366.2 MB)
17/11/20 01:05:13 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64500 in memory (size: 3.7 KB, free: 366.3 MB)
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 55
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 56
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 57
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 58
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 59
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 60
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 61
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 62
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 63
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 64
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 65
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 66
17/11/20 01:05:13 INFO ContextCleaner: Cleaned shuffle 0
17/11/20 01:05:13 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:64500 in memory (size: 11.0 KB, free: 366.3 MB)
17/11/20 01:05:13 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64500 in memory (size: 3.7 KB, free: 366.3 MB)
17/11/20 01:05:13 INFO ContextCleaner: Cleaned accumulator 163
17/11/20 01:05:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars`
17/11/20 01:05:23 WARN H2OContext: Method H2OContext.getOrCreate with an argument of type SparkContext is deprecated and parameter of type SparkSession is preferred.
17/11/20 01:05:23 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/11/20 01:05:23 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/11/20 01:05:23 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-Macbook_local-1511139901370
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/11/20 01:05:23 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/11/20 01:05:23 INFO DAGScheduler: Got job 3 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/11/20 01:05:23 INFO DAGScheduler: Final stage: ResultStage 5 (collect at SpreadRDDBuilder.scala:105)
17/11/20 01:05:23 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:05:23 INFO DAGScheduler: Missing parents: List()
17/11/20 01:05:23 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/11/20 01:05:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.1 KB, free 366.0 MB)
17/11/20 01:05:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1361.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64500 (size: 1361.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:23 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/11/20 01:05:23 INFO TaskSchedulerImpl: Adding task set 5.0 with 11 tasks
17/11/20 01:05:23 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 7, localhost, executor driver, partition 2, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 8, localhost, executor driver, partition 3, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/11/20 01:05:23 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/11/20 01:05:23 INFO Executor: Running task 2.0 in stage 5.0 (TID 7)
17/11/20 01:05:23 INFO Executor: Running task 3.0 in stage 5.0 (TID 8)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_0 stored as values in memory (estimated size 16.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_0 in memory on 127.0.0.1:64500 (size: 16.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_2 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_1 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_2 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_1 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_3 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_3 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 5:
[rdd_26_0]
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_26_3]
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 7:
[rdd_26_2]
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 6:
[rdd_26_1]
17/11/20 01:05:23 INFO Executor: Finished task 2.0 in stage 5.0 (TID 7). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO Executor: Finished task 3.0 in stage 5.0 (TID 8). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 9, localhost, executor driver, partition 4, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 7) in 32 ms on localhost (executor driver) (1/11)
17/11/20 01:05:23 INFO Executor: Running task 4.0 in stage 5.0 (TID 9)
17/11/20 01:05:23 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 10, localhost, executor driver, partition 5, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO Executor: Running task 5.0 in stage 5.0 (TID 10)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_4 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 11, localhost, executor driver, partition 6, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_4 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO Executor: Running task 6.0 in stage 5.0 (TID 11)
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 9:
[rdd_26_4]
17/11/20 01:05:23 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 12, localhost, executor driver, partition 7, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_5 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 8) in 39 ms on localhost (executor driver) (2/11)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_5 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO Executor: Running task 7.0 in stage 5.0 (TID 12)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 49 ms on localhost (executor driver) (3/11)
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 10:
[rdd_26_5]
17/11/20 01:05:23 INFO Executor: Finished task 4.0 in stage 5.0 (TID 9). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO Executor: Finished task 5.0 in stage 5.0 (TID 10). 1883 bytes result sent to driver
17/11/20 01:05:23 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 13, localhost, executor driver, partition 8, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 14, localhost, executor driver, partition 9, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 INFO Executor: Running task 8.0 in stage 5.0 (TID 13)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 9) in 14 ms on localhost (executor driver) (4/11)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 47 ms on localhost (executor driver) (5/11)
17/11/20 01:05:23 INFO Executor: Running task 9.0 in stage 5.0 (TID 14)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 10) in 13 ms on localhost (executor driver) (6/11)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_7 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_7 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_6 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 12:
[rdd_26_7]
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_9 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO Executor: Finished task 7.0 in stage 5.0 (TID 12). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_6 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_9 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 15, localhost, executor driver, partition 10, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 11:
[rdd_26_6]
17/11/20 01:05:23 INFO Executor: Finished task 6.0 in stage 5.0 (TID 11). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO Executor: Running task 10.0 in stage 5.0 (TID 15)
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 14:
[rdd_26_9]
17/11/20 01:05:23 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 12) in 15 ms on localhost (executor driver) (7/11)
17/11/20 01:05:23 INFO Executor: Finished task 9.0 in stage 5.0 (TID 14). 1796 bytes result sent to driver
17/11/20 01:05:23 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 11) in 19 ms on localhost (executor driver) (8/11)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 14) in 11 ms on localhost (executor driver) (9/11)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_10 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO MemoryStore: Block rdd_26_8 stored as values in memory (estimated size 24.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_10 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added rdd_26_8 in memory on 127.0.0.1:64500 (size: 24.0 B, free: 366.3 MB)
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 15:
[rdd_26_10]
17/11/20 01:05:23 INFO Executor: Finished task 10.0 in stage 5.0 (TID 15). 1796 bytes result sent to driver
17/11/20 01:05:23 WARN Executor: 1 block locks were not released by TID = 13:
[rdd_26_8]
17/11/20 01:05:23 INFO Executor: Finished task 8.0 in stage 5.0 (TID 13). 1883 bytes result sent to driver
17/11/20 01:05:23 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 15) in 11 ms on localhost (executor driver) (10/11)
17/11/20 01:05:23 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 13) in 20 ms on localhost (executor driver) (11/11)
17/11/20 01:05:23 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/11/20 01:05:23 INFO DAGScheduler: ResultStage 5 (collect at SpreadRDDBuilder.scala:105) finished in 0.071 s
17/11/20 01:05:23 INFO DAGScheduler: Job 3 finished: collect at SpreadRDDBuilder.scala:105, took 0.080144 s
17/11/20 01:05:23 INFO ParallelCollectionRDD: Removing RDD 26 from persistence list
17/11/20 01:05:23 INFO BlockManager: Removing RDD 26
17/11/20 01:05:23 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/11/20 01:05:23 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/11/20 01:05:23 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/11/20 01:05:23 INFO DAGScheduler: Got job 4 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/11/20 01:05:23 INFO DAGScheduler: Final stage: ResultStage 6 (collect at InternalBackendUtils.scala:163)
17/11/20 01:05:23 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:05:23 INFO DAGScheduler: Missing parents: List()
17/11/20 01:05:23 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[29] at map at InternalBackendUtils.scala:100), which has no missing parents
17/11/20 01:05:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.0 KB, free 366.0 MB)
17/11/20 01:05:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1962.0 B, free 366.0 MB)
17/11/20 01:05:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64500 (size: 1962.0 B, free: 366.3 MB)
17/11/20 01:05:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[29] at map at InternalBackendUtils.scala:100)
17/11/20 01:05:23 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/11/20 01:05:23 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 16, localhost, executor driver, partition 0, ANY, 11562 bytes)
17/11/20 01:05:23 INFO Executor: Running task 0.0 in stage 6.0 (TID 16)
17/11/20 01:05:23 INFO NativeLibrary: Loaded XGBoost library from lib/osx_64/libxgboost4j.dylib (/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/libxgboost4j3935258677668764558.dylib)
17/11/20 01:05:24 INFO Server: jetty-8.1.17.v20150415
17/11/20 01:05:24 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54321
17/11/20 01:05:24 INFO Executor: Finished task 0.0 in stage 6.0 (TID 16). 1540 bytes result sent to driver
17/11/20 01:05:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 16) in 1401 ms on localhost (executor driver) (1/1)
17/11/20 01:05:24 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/11/20 01:05:24 INFO DAGScheduler: ResultStage 6 (collect at InternalBackendUtils.scala:163) finished in 1.402 s
17/11/20 01:05:24 INFO DAGScheduler: Job 4 finished: collect at InternalBackendUtils.scala:163, took 1.409925 s
17/11/20 01:05:24 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/11/20 01:05:24 INFO DAGScheduler: Got job 5 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/11/20 01:05:24 INFO DAGScheduler: Final stage: ResultStage 7 (foreach at InternalBackendUtils.scala:175)
17/11/20 01:05:24 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:05:24 INFO DAGScheduler: Missing parents: List()
17/11/20 01:05:24 INFO DAGScheduler: Submitting ResultStage 7 (InvokeOnNodesRDD[28] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/11/20 01:05:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1672.0 B, free 366.0 MB)
17/11/20 01:05:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1161.0 B, free 366.0 MB)
17/11/20 01:05:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64500 (size: 1161.0 B, free: 366.3 MB)
17/11/20 01:05:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (InvokeOnNodesRDD[28] at RDD at InvokeOnNodesRDD.scala:27)
17/11/20 01:05:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/11/20 01:05:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 17, localhost, executor driver, partition 0, ANY, 11562 bytes)
17/11/20 01:05:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 17)
17/11/20 01:05:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 17). 1012 bytes result sent to driver
17/11/20 01:05:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 17) in 8 ms on localhost (executor driver) (1/1)
17/11/20 01:05:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/11/20 01:05:24 INFO DAGScheduler: ResultStage 7 (foreach at InternalBackendUtils.scala:175) finished in 0.009 s
17/11/20 01:05:24 INFO DAGScheduler: Job 5 finished: foreach at InternalBackendUtils.scala:175, took 0.015354 s
17/11/20 01:05:24 INFO BlockManager: Removing RDD 26
17/11/20 01:05:24 INFO ContextCleaner: Cleaned RDD 26
17/11/20 01:05:24 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64500 in memory (size: 1361.0 B, free: 366.3 MB)
17/11/20 01:05:24 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:64500 in memory (size: 1962.0 B, free: 366.3 MB)
17/11/20 01:05:24 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:64500 in memory (size: 1161.0 B, free: 366.3 MB)
17/11/20 01:05:25 INFO ContextCleaner: Cleaned accumulator 560
17/11/20 01:05:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64500 in memory (size: 4.6 KB, free: 366.3 MB)
17/11/20 01:05:32 INFO ContextCleaner: Cleaned accumulator 1
17/11/20 01:05:32 INFO ContextCleaner: Cleaned accumulator 0
17/11/20 01:05:35 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-Macbook_local-1511139901370
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54321)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54321 (CMD + click in Mac OSX)

    
17/11/20 01:05:36 INFO SparkContext: Starting job: runJob at WriteConverterCtxUtils.scala:85
17/11/20 01:05:36 INFO DAGScheduler: Got job 6 (runJob at WriteConverterCtxUtils.scala:85) with 1 output partitions
17/11/20 01:05:36 INFO DAGScheduler: Final stage: ResultStage 8 (runJob at WriteConverterCtxUtils.scala:85)
17/11/20 01:05:36 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:05:36 INFO DAGScheduler: Missing parents: List()
17/11/20 01:05:36 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[32] at rdd at SparkDataFrameConverter.scala:59), which has no missing parents
17/11/20 01:05:36 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 21.1 KB, free 366.0 MB)
17/11/20 01:05:36 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 10.3 KB, free 365.9 MB)
17/11/20 01:05:36 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64500 (size: 10.3 KB, free: 366.3 MB)
17/11/20 01:05:36 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[32] at rdd at SparkDataFrameConverter.scala:59)
17/11/20 01:05:36 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/11/20 01:05:36 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 12134 bytes)
17/11/20 01:05:36 INFO Executor: Running task 0.0 in stage 8.0 (TID 18)
17/11/20 01:05:36 INFO BlockManager: Found block rdd_9_0 locally
17/11/20 01:05:36 INFO CodeGenerator: Code generated in 25.485273 ms
17/11/20 01:05:36 INFO CodeGenerator: Code generated in 14.581986 ms
17/11/20 01:05:36 INFO Executor: Finished task 0.0 in stage 8.0 (TID 18). 1708 bytes result sent to driver
17/11/20 01:05:36 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 18) in 140 ms on localhost (executor driver) (1/1)
17/11/20 01:05:36 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/11/20 01:05:36 INFO DAGScheduler: ResultStage 8 (runJob at WriteConverterCtxUtils.scala:85) finished in 0.140 s
17/11/20 01:05:36 INFO DAGScheduler: Job 6 finished: runJob at WriteConverterCtxUtils.scala:85, took 0.157191 s
17/11/20 01:05:37 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64500 in memory (size: 10.3 KB, free: 366.3 MB)
17/11/20 01:05:37 INFO ContextCleaner: Cleaned accumulator 657
17/11/20 01:05:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:05:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:05:51 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 01:05:51 INFO DAGScheduler: Got job 7 (collect at utils.scala:58) with 1 output partitions
17/11/20 01:05:51 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:58)
17/11/20 01:05:51 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:05:51 INFO DAGScheduler: Missing parents: List()
17/11/20 01:05:51 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at map at utils.scala:55), which has no missing parents
17/11/20 01:05:51 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 366.0 MB)
17/11/20 01:05:51 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.0 MB)
17/11/20 01:05:51 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64500 (size: 4.6 KB, free: 366.3 MB)
17/11/20 01:05:51 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/11/20 01:05:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at map at utils.scala:55)
17/11/20 01:05:51 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/11/20 01:05:51 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 11910 bytes)
17/11/20 01:05:51 INFO Executor: Running task 0.0 in stage 9.0 (TID 19)
17/11/20 01:05:51 INFO Executor: Finished task 0.0 in stage 9.0 (TID 19). 1240 bytes result sent to driver
17/11/20 01:05:51 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 19) in 9 ms on localhost (executor driver) (1/1)
17/11/20 01:05:51 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/11/20 01:05:51 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:58) finished in 0.010 s
17/11/20 01:05:51 INFO DAGScheduler: Job 7 finished: collect at utils.scala:58, took 0.018094 s
17/11/20 01:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:06:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:06:05 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 01:06:05 INFO DAGScheduler: Got job 8 (collect at utils.scala:58) with 1 output partitions
17/11/20 01:06:05 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/11/20 01:06:05 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:06:05 INFO DAGScheduler: Missing parents: List()
17/11/20 01:06:05 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at map at utils.scala:55), which has no missing parents
17/11/20 01:06:05 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.7 KB, free 366.0 MB)
17/11/20 01:06:05 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.0 MB)
17/11/20 01:06:05 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64500 (size: 4.6 KB, free: 366.3 MB)
17/11/20 01:06:05 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/11/20 01:06:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at map at utils.scala:55)
17/11/20 01:06:05 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/11/20 01:06:05 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 11910 bytes)
17/11/20 01:06:05 INFO Executor: Running task 0.0 in stage 10.0 (TID 20)
17/11/20 01:06:05 INFO Executor: Finished task 0.0 in stage 10.0 (TID 20). 1240 bytes result sent to driver
17/11/20 01:06:05 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 20) in 13 ms on localhost (executor driver) (1/1)
17/11/20 01:06:05 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/11/20 01:06:05 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.014 s
17/11/20 01:06:05 INFO DAGScheduler: Job 8 finished: collect at utils.scala:58, took 0.020987 s
17/11/20 01:06:29 INFO SparkContext: Invoking stop() from shutdown hook
17/11/20 01:06:30 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/11/20 01:06:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/11/20 01:06:30 INFO MemoryStore: MemoryStore cleared
17/11/20 01:06:30 INFO BlockManager: BlockManager stopped
17/11/20 01:06:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/11/20 01:06:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/11/20 01:06:30 INFO SparkContext: Successfully stopped SparkContext
17/11/20 01:06:30 INFO ShutdownHookManager: Shutdown hook called
17/11/20 01:06:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-200de459-4bc3-400d-933a-7f67b11381ef
17/11/20 01:06:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913
17/11/20 01:06:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/repl-6fee413a-57df-40de-97be-f33c8017012a
17/11/20 01:06:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-fadc53b2-a1fa-4611-828e-2fdc5d135913/repl-83ab706f-3c23-432c-ae85-68b891dd8310
17/11/20 01:07:04 INFO SparkContext: Running Spark version 2.1.0
17/11/20 01:07:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/11/20 01:07:04 INFO SecurityManager: Changing view acls to: Macbook
17/11/20 01:07:04 INFO SecurityManager: Changing modify acls to: Macbook
17/11/20 01:07:04 INFO SecurityManager: Changing view acls groups to: 
17/11/20 01:07:04 INFO SecurityManager: Changing modify acls groups to: 
17/11/20 01:07:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Macbook); groups with view permissions: Set(); users  with modify permissions: Set(Macbook); groups with modify permissions: Set()
17/11/20 01:07:04 INFO Utils: Successfully started service 'sparkDriver' on port 64993.
17/11/20 01:07:04 INFO SparkEnv: Registering MapOutputTracker
17/11/20 01:07:04 INFO SparkEnv: Registering BlockManagerMaster
17/11/20 01:07:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/11/20 01:07:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/11/20 01:07:04 INFO DiskBlockManager: Created local directory at /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/blockmgr-bc393a78-ff02-42b7-8f35-f0b734c44c0b
17/11/20 01:07:04 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/11/20 01:07:04 INFO SparkEnv: Registering OutputCommitCoordinator
17/11/20 01:07:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/11/20 01:07:05 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.14.jar at spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-core_2.11-2.1.14.jar with timestamp 1511140025178
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.14.jar at spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-ml_2.11-2.1.14.jar with timestamp 1511140025179
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.14.jar at spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-repl_2.11-2.1.14.jar with timestamp 1511140025179
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:64993/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1511140025179
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-genmodel-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-genmodel-3.14.0.2.jar with timestamp 1511140025179
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-core-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-core-3.14.0.2.jar with timestamp 1511140025179
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-algos-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-algos-3.14.0.2.jar with timestamp 1511140025179
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-web-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-web-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-ext-xgboost-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-ext-xgboost-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-scala_2.11-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-persist-hdfs-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-persist-s3-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-persist-s3-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-automl-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-automl-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:64993/jars/org.joda_joda-convert-1.7.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:64993/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1511140025180
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.google.code.gson_gson-2.6.2.jar at spark://127.0.0.1:64993/jars/com.google.code.gson_gson-2.6.2.jar with timestamp 1511140025181
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar at spark://127.0.0.1:64993/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar with timestamp 1511140025181
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.4.jar at spark://127.0.0.1:64993/jars/ai.h2o_deepwater-backend-api-1.0.4.jar with timestamp 1511140025181
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.slf4j_slf4j-log4j12-1.7.5.jar at spark://127.0.0.1:64993/jars/org.slf4j_slf4j-log4j12-1.7.5.jar with timestamp 1511140025181
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar at spark://127.0.0.1:64993/jars/org.slf4j_slf4j-api-1.7.5.jar with timestamp 1511140025181
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/log4j_log4j-1.2.17.jar at spark://127.0.0.1:64993/jars/log4j_log4j-1.2.17.jar with timestamp 1511140025181
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:64993/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1511140025181
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:64993/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:64993/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:64993/jars/commons-io_commons-io-2.4.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:64993/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:64993/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/ai.h2o_h2o-jaas-pam-3.14.0.2.jar at spark://127.0.0.1:64993/jars/ai.h2o_h2o-jaas-pam-3.14.0.2.jar with timestamp 1511140025182
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:64993/jars/com.google.guava_guava-16.0.1.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:64993/jars/commons-lang_commons-lang-2.6.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.kohsuke_libpam4j-1.8.jar at spark://127.0.0.1:64993/jars/org.kohsuke_libpam4j-1.8.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/net.java.dev.jna_jna-4.0.0.jar at spark://127.0.0.1:64993/jars/net.java.dev.jna_jna-4.0.0.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1511140025184
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:64993/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:64993/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.21.jar at spark://127.0.0.1:64993/jars/com.esotericsoftware.kryo_kryo-2.21.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar at spark://127.0.0.1:64993/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.esotericsoftware.minlog_minlog-1.2.jar at spark://127.0.0.1:64993/jars/com.esotericsoftware.minlog_minlog-1.2.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.objenesis_objenesis-1.2.jar at spark://127.0.0.1:64993/jars/org.objenesis_objenesis-1.2.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.ow2.asm_asm-4.0.jar at spark://127.0.0.1:64993/jars/org.ow2.asm_asm-4.0.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:64993/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1511140025185
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:64993/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:64993/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:64993/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:64993/jars/joda-time_joda-time-2.8.1.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:64993/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:64993/jars/commons-codec_commons-codec-1.6.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO SparkContext: Added JAR file:/Users/Macbook/Library/R/3.4/library/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64993/jars/sparklyr-2.1-2.11.jar with timestamp 1511140025186
17/11/20 01:07:05 INFO Executor: Starting executor ID driver on host localhost
17/11/20 01:07:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64994.
17/11/20 01:07:05 INFO NettyBlockTransferService: Server created on 127.0.0.1:64994
17/11/20 01:07:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/11/20 01:07:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64994, None)
17/11/20 01:07:05 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64994 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64994, None)
17/11/20 01:07:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64994, None)
17/11/20 01:07:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64994, None)
17/11/20 01:07:05 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/11/20 01:07:05 INFO SharedState: Warehouse path is 'file:/Users/Macbook/Documents/Study/study_R/spark-warehouse'.
17/11/20 01:07:05 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/11/20 01:07:06 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/11/20 01:07:06 INFO ObjectStore: ObjectStore, initialize called
17/11/20 01:07:06 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/11/20 01:07:06 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/11/20 01:07:08 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/11/20 01:07:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:07:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:07:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:07:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:07:10 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/11/20 01:07:10 INFO ObjectStore: Initialized ObjectStore
17/11/20 01:07:10 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/11/20 01:07:10 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/11/20 01:07:11 INFO HiveMetaStore: Added admin role in metastore
17/11/20 01:07:11 INFO HiveMetaStore: Added public role in metastore
17/11/20 01:07:11 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/11/20 01:07:11 INFO HiveMetaStore: 0: get_all_databases
17/11/20 01:07:11 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_all_databases	
17/11/20 01:07:11 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/11/20 01:07:11 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/11/20 01:07:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/11/20 01:07:11 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/7c758572-b342-4e6f-bc0e-cea90f41a8c1_resources
17/11/20 01:07:11 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/7c758572-b342-4e6f-bc0e-cea90f41a8c1
17/11/20 01:07:11 INFO SessionState: Created local directory: /var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/Macbook/7c758572-b342-4e6f-bc0e-cea90f41a8c1
17/11/20 01:07:11 INFO SessionState: Created HDFS directory: /tmp/hive/Macbook/7c758572-b342-4e6f-bc0e-cea90f41a8c1/_tmp_space.db
17/11/20 01:07:11 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/Macbook/Documents/Study/study_R/spark-warehouse
17/11/20 01:07:11 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:07:11 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:07:11 INFO HiveMetaStore: 0: get_database: global_temp
17/11/20 01:07:11 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/11/20 01:07:11 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/11/20 01:07:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:07:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:07:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:07:13 INFO HiveMetaStore: 0: get_database: default
17/11/20 01:07:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_database: default	
17/11/20 01:07:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/11/20 01:07:13 INFO audit: ugi=Macbook	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/11/20 01:07:14 INFO CodeGenerator: Code generated in 178.263967 ms
17/11/20 01:07:14 INFO SparkContext: Starting job: collect at utils.scala:58
17/11/20 01:07:14 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/11/20 01:07:14 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/11/20 01:07:14 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:07:14 INFO DAGScheduler: Missing parents: List()
17/11/20 01:07:14 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/11/20 01:07:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/11/20 01:07:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/11/20 01:07:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64994 (size: 4.6 KB, free: 366.3 MB)
17/11/20 01:07:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/11/20 01:07:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/11/20 01:07:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11596 bytes)
17/11/20 01:07:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/11/20 01:07:14 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.kohsuke_libpam4j-1.8.jar with timestamp 1511140025184
17/11/20 01:07:14 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64993 after 17 ms (0 ms spent in bootstraps)
17/11/20 01:07:14 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.kohsuke_libpam4j-1.8.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5337631651746635168.tmp
17/11/20 01:07:14 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.kohsuke_libpam4j-1.8.jar to class loader
17/11/20 01:07:14 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1511140025186
17/11/20 01:07:14 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6165357986960218649.tmp
17/11/20 01:07:14 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/11/20 01:07:14 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1511140025185
17/11/20 01:07:14 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-queries-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1529526835836614092.tmp
17/11/20 01:07:14 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/11/20 01:07:14 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1511140025184
17/11/20 01:07:14 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp3551185394780581385.tmp
17/11/20 01:07:14 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/11/20 01:07:14 INFO Executor: Fetching spark://127.0.0.1:64993/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1511140025185
17/11/20 01:07:14 INFO Utils: Fetching spark://127.0.0.1:64993/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp7803152639894639735.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp635692305209613849.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.javassist_javassist-3.18.2-GA.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4961415907996987025.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.javassist_javassist-3.18.2-GA.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/joda-time_joda-time-2.8.1.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/joda-time_joda-time-2.8.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5496221118818018192.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/joda-time_joda-time-2.8.1.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1669950290932322844.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4514248779508197708.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.github.rwl_jtransforms-2.4.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp800563467433009927.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/sparklyr-2.1-2.11.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/sparklyr-2.1-2.11.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1246921447914405792.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/sparklyr-2.1-2.11.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.slf4j_slf4j-api-1.7.5.jar with timestamp 1511140025181
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.slf4j_slf4j-api-1.7.5.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp8714148220731491830.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.slf4j_slf4j-api-1.7.5.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-core-3.14.0.2.jar with timestamp 1511140025179
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-core-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp2574151096269052039.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-core-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4330747307258553550.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp8210308278246421537.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.esotericsoftware.reflectasm_reflectasm-1.07.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.google.code.gson_gson-2.6.2.jar with timestamp 1511140025181
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.google.code.gson_gson-2.6.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6572930723101424894.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.google.code.gson_gson-2.6.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_deepwater-backend-api-1.0.4.jar with timestamp 1511140025181
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_deepwater-backend-api-1.0.4.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4264427795918545432.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_deepwater-backend-api-1.0.4.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-ext-xgboost-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-ext-xgboost-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4584897842156958939.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-ext-xgboost-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp3416668823525081821.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/commons-logging_commons-logging-1.1.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4193860422716404492.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/commons-logging_commons-logging-1.1.3.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1539486977575989394.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.mapdb_mapdb-0.9.9.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5702201579188719786.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.mapdb_mapdb-0.9.9.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.joda_joda-convert-1.7.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.joda_joda-convert-1.7.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp2193376240510559446.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.joda_joda-convert-1.7.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.slf4j_slf4j-log4j12-1.7.5.jar with timestamp 1511140025181
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.slf4j_slf4j-log4j12-1.7.5.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1898796052325855367.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.slf4j_slf4j-log4j12-1.7.5.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.objenesis_objenesis-1.2.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.objenesis_objenesis-1.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4993903090514381396.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.objenesis_objenesis-1.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/commons-codec_commons-codec-1.6.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/commons-codec_commons-codec-1.6.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1579197585714716383.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/commons-codec_commons-codec-1.6.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/commons-httpclient_commons-httpclient-3.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp8990674530277695015.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp8549049157300400730.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.esotericsoftware.kryo_kryo-2.21.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.esotericsoftware.kryo_kryo-2.21.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp8279160492178495670.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.esotericsoftware.kryo_kryo-2.21.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-core-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp729952557251051215.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/commons-lang_commons-lang-2.6.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/commons-lang_commons-lang-2.6.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp15070504138625600.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/commons-lang_commons-lang-2.6.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-web-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-web-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp3812378814957697083.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-web-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp3743060695556161066.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp7114735243202583696.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1511140025181
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/gov.nist.math_jama-1.0.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6429038597321514344.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/gov.nist.math_jama-1.0.3.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-persist-s3-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-persist-s3-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5760651150654809417.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-persist-s3-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-core_2.11-2.1.14.jar with timestamp 1511140025178
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-core_2.11-2.1.14.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1158055392762760519.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_sparkling-water-core_2.11-2.1.14.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-algos-3.14.0.2.jar with timestamp 1511140025179
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-algos-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1484061624569942180.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-algos-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5323205182321326611.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-genmodel-ext-xgboost-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/net.java.dev.jna_jna-4.0.0.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/net.java.dev.jna_jna-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp7214032883087714960.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/net.java.dev.jna_jna-4.0.0.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-scala_2.11-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-scala_2.11-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp3316511224157846198.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-scala_2.11-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-automl-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-automl-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4018239980759869125.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-automl-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5174630917327455399.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/net.sf.opencsv_opencsv-2.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6093440752844630358.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/net.sf.opencsv_opencsv-2.3.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-ml_2.11-2.1.14.jar with timestamp 1511140025179
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-ml_2.11-2.1.14.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4684316256367552587.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_sparkling-water-ml_2.11-2.1.14.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp7678883149543791301.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5076852442101371137.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1511140025179
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/no.priv.garshol.duke_duke-1.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp7436401881314378285.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/no.priv.garshol.duke_duke-1.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp5770030916896726721.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.esotericsoftware.minlog_minlog-1.2.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.esotericsoftware.minlog_minlog-1.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6455834497661955865.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.esotericsoftware.minlog_minlog-1.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.apache.commons_commons-math3-3.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp406545339447278657.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.apache.commons_commons-math3-3.3.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp303565176157670928.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.google.guava_guava-16.0.1.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.google.guava_guava-16.0.1.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6941311247164485021.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.google.guava_guava-16.0.1.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1511140025183
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp8571315600509041712.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-genmodel-3.14.0.2.jar with timestamp 1511140025179
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-genmodel-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp2953974465611586647.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-genmodel-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1651334550294223297.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1945843869940049155.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/commons-io_commons-io-2.4.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/commons-io_commons-io-2.4.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4931791087330438417.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/commons-io_commons-io-2.4.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp7533589060294692009.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.ow2.asm_asm-4.0.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.ow2.asm_asm-4.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp8441361320520141165.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.ow2.asm_asm-4.0.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6238130590856284260.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-persist-hdfs-3.14.0.2.jar with timestamp 1511140025180
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-persist-hdfs-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1587754825167444782.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-persist-hdfs-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar with timestamp 1511140025181
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6662936872217607683.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.google.protobuf.nano_protobuf-javanano-3.1.0.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1511140025185
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/com.spatial4j_spatial4j-0.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6122767991962958316.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/com.spatial4j_spatial4j-0.3.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-repl_2.11-2.1.14.jar with timestamp 1511140025179
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_sparkling-water-repl_2.11-2.1.14.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp833287960408648847.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_sparkling-water-repl_2.11-2.1.14.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-jaas-pam-3.14.0.2.jar with timestamp 1511140025182
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/ai.h2o_h2o-jaas-pam-3.14.0.2.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1648713764036175224.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/ai.h2o_h2o-jaas-pam-3.14.0.2.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1511140025186
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp4272602492515018425.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/log4j_log4j-1.2.17.jar with timestamp 1511140025181
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/log4j_log4j-1.2.17.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp2794227041239419059.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/log4j_log4j-1.2.17.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp1851269732965237265.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/11/20 01:07:15 INFO Executor: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1511140025184
17/11/20 01:07:15 INFO Utils: Fetching spark://127.0.0.1:64993/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to /private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/fetchFileTemp6926340979369975291.tmp
17/11/20 01:07:15 INFO Executor: Adding file:/private/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/spark-6af85da4-0cad-4a67-98a4-01db316ca32a/userFiles-c0da18ee-b02f-46c5-8ae6-625aa5d9b3fa/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/11/20 01:07:15 INFO CodeGenerator: Code generated in 16.337313 ms
17/11/20 01:07:16 INFO CodeGenerator: Code generated in 16.324353 ms
17/11/20 01:07:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/11/20 01:07:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1250 ms on localhost (executor driver) (1/1)
17/11/20 01:07:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/11/20 01:07:16 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 1.272 s
17/11/20 01:07:16 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 1.426133 s
17/11/20 01:07:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:07:16 INFO SparkSqlParser: Parsing command: mtcars
17/11/20 01:07:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:07:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
17/11/20 01:07:16 INFO SparkSqlParser: Parsing command: `mtcars`
17/11/20 01:07:16 INFO FileSourceStrategy: Pruning directories with: 
17/11/20 01:07:16 INFO FileSourceStrategy: Post-Scan Filters: 
17/11/20 01:07:16 INFO FileSourceStrategy: Output Data Schema: struct<mpg: double, cyl: double, disp: double, hp: double, drat: double ... 9 more fields>
17/11/20 01:07:16 INFO FileSourceStrategy: Pushed Filters: 
17/11/20 01:07:16 INFO CodeGenerator: Code generated in 7.212985 ms
17/11/20 01:07:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 300.8 KB, free 366.0 MB)
17/11/20 01:07:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 366.0 MB)
17/11/20 01:07:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64994 (size: 25.4 KB, free: 366.3 MB)
17/11/20 01:07:16 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/11/20 01:07:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/11/20 01:07:16 INFO CodeGenerator: Code generated in 12.886338 ms
17/11/20 01:07:16 INFO CodeGenerator: Code generated in 11.582878 ms
17/11/20 01:07:16 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/11/20 01:07:16 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:07:16 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/11/20 01:07:16 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:07:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/11/20 01:07:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/11/20 01:07:16 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 01:07:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 23.2 KB, free 365.9 MB)
17/11/20 01:07:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/11/20 01:07:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64994 (size: 11.0 KB, free: 366.3 MB)
17/11/20 01:07:16 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:07:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/11/20 01:07:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12245 bytes)
17/11/20 01:07:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/11/20 01:07:16 INFO FileScanRDD: Reading File path: file:///var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/RtmpJ27xzq/spark_serialize_600df8759318fe0d3e7cd227dfb889264b9395236a2336b9c1d32f83ed509279.csv, range: 0-1303, partition values: [empty row]
17/11/20 01:07:17 INFO CodeGenerator: Code generated in 19.153004 ms
17/11/20 01:07:17 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 4.2 KB, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:64994 (size: 4.2 KB, free: 366.3 MB)
17/11/20 01:07:17 INFO CodeGenerator: Code generated in 6.083118 ms
17/11/20 01:07:17 INFO CodeGenerator: Code generated in 27.831509 ms
17/11/20 01:07:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2997 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 292 ms on localhost (executor driver) (1/1)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/11/20 01:07:17 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.294 s
17/11/20 01:07:17 INFO DAGScheduler: looking for newly runnable stages
17/11/20 01:07:17 INFO DAGScheduler: running: Set()
17/11/20 01:07:17 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/11/20 01:07:17 INFO DAGScheduler: failed: Set()
17/11/20 01:07:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64994 (size: 3.7 KB, free: 366.3 MB)
17/11/20 01:07:17 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/11/20 01:07:17 INFO ContextCleaner: Cleaned accumulator 54
17/11/20 01:07:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 11508 bytes)
17/11/20 01:07:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/11/20 01:07:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 01:07:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
17/11/20 01:07:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 46 ms on localhost (executor driver) (1/1)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/11/20 01:07:17 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.047 s
17/11/20 01:07:17 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.422283 s
17/11/20 01:07:17 INFO CodeGenerator: Code generated in 8.371846 ms
17/11/20 01:07:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:07:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
17/11/20 01:07:17 INFO SparkContext: Starting job: collect at utils.scala:210
17/11/20 01:07:17 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:210)
17/11/20 01:07:17 INFO DAGScheduler: Got job 2 (collect at utils.scala:210) with 1 output partitions
17/11/20 01:07:17 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:210)
17/11/20 01:07:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/11/20 01:07:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/11/20 01:07:17 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210), which has no missing parents
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 23.2 KB, free 365.9 MB)
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.0 KB, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64994 (size: 11.0 KB, free: 366.2 MB)
17/11/20 01:07:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:210)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/11/20 01:07:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 12237 bytes)
17/11/20 01:07:17 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/11/20 01:07:17 INFO BlockManager: Found block rdd_9_0 locally
17/11/20 01:07:17 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2188 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 17 ms on localhost (executor driver) (1/1)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/11/20 01:07:17 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:210) finished in 0.017 s
17/11/20 01:07:17 INFO DAGScheduler: looking for newly runnable stages
17/11/20 01:07:17 INFO DAGScheduler: running: Set()
17/11/20 01:07:17 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/11/20 01:07:17 INFO DAGScheduler: failed: Set()
17/11/20 01:07:17 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210), which has no missing parents
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64994 (size: 3.7 KB, free: 366.2 MB)
17/11/20 01:07:17 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:210)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/11/20 01:07:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 11500 bytes)
17/11/20 01:07:17 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/11/20 01:07:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/11/20 01:07:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/11/20 01:07:17 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 9 ms on localhost (executor driver) (1/1)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/11/20 01:07:17 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:210) finished in 0.010 s
17/11/20 01:07:17 INFO DAGScheduler: Job 2 finished: collect at utils.scala:210, took 0.050983 s
17/11/20 01:07:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:07:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz1`
WHERE (0 = 1)
17/11/20 01:07:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:07:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars`
17/11/20 01:07:17 WARN H2OContext: Method H2OContext.getOrCreate with an argument of type SparkContext is deprecated and parameter of type SparkSession is preferred.
17/11/20 01:07:17 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/11/20 01:07:17 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/11/20 01:07:17 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-Macbook_local-1511140025260
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/11/20 01:07:17 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/11/20 01:07:17 INFO DAGScheduler: Got job 3 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/11/20 01:07:17 INFO DAGScheduler: Final stage: ResultStage 5 (collect at SpreadRDDBuilder.scala:105)
17/11/20 01:07:17 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:07:17 INFO DAGScheduler: Missing parents: List()
17/11/20 01:07:17 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.1 KB, free 365.9 MB)
17/11/20 01:07:17 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1361.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64994 (size: 1361.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:17 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Adding task set 5.0 with 11 tasks
17/11/20 01:07:17 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 7, localhost, executor driver, partition 2, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 8, localhost, executor driver, partition 3, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/11/20 01:07:17 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/11/20 01:07:17 INFO Executor: Running task 2.0 in stage 5.0 (TID 7)
17/11/20 01:07:17 INFO Executor: Running task 3.0 in stage 5.0 (TID 8)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_1 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_3 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_1 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 16.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_3 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_0 in memory on 127.0.0.1:64994 (size: 16.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_2 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_2 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 7:
[rdd_23_2]
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 6:
[rdd_23_1]
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 5:
[rdd_23_0]
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 8:
[rdd_23_3]
17/11/20 01:07:17 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO Executor: Finished task 2.0 in stage 5.0 (TID 7). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO Executor: Finished task 3.0 in stage 5.0 (TID 8). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 9, localhost, executor driver, partition 4, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO Executor: Running task 4.0 in stage 5.0 (TID 9)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 34 ms on localhost (executor driver) (1/11)
17/11/20 01:07:17 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 10, localhost, executor driver, partition 5, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_4 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO Executor: Running task 5.0 in stage 5.0 (TID 10)
17/11/20 01:07:17 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 11, localhost, executor driver, partition 6, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 7) in 38 ms on localhost (executor driver) (2/11)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_4 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 46 ms on localhost (executor driver) (3/11)
17/11/20 01:07:17 INFO Executor: Running task 6.0 in stage 5.0 (TID 11)
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 9:
[rdd_23_4]
17/11/20 01:07:17 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 8) in 38 ms on localhost (executor driver) (4/11)
17/11/20 01:07:17 INFO Executor: Finished task 4.0 in stage 5.0 (TID 9). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 12, localhost, executor driver, partition 7, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO Executor: Running task 7.0 in stage 5.0 (TID 12)
17/11/20 01:07:17 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 13, localhost, executor driver, partition 8, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO Executor: Running task 8.0 in stage 5.0 (TID 13)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_6 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_7 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_8 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 9) in 12 ms on localhost (executor driver) (5/11)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_5 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_6 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_7 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 11:
[rdd_23_6]
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_8 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 12:
[rdd_23_7]
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_5 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO Executor: Finished task 6.0 in stage 5.0 (TID 11). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO Executor: Finished task 7.0 in stage 5.0 (TID 12). 1796 bytes result sent to driver
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 13:
[rdd_23_8]
17/11/20 01:07:17 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 14, localhost, executor driver, partition 9, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 10:
[rdd_23_5]
17/11/20 01:07:17 INFO Executor: Finished task 8.0 in stage 5.0 (TID 13). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO Executor: Running task 9.0 in stage 5.0 (TID 14)
17/11/20 01:07:17 INFO Executor: Finished task 5.0 in stage 5.0 (TID 10). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 15, localhost, executor driver, partition 10, PROCESS_LOCAL, 11570 bytes)
17/11/20 01:07:17 INFO Executor: Running task 10.0 in stage 5.0 (TID 15)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 13) in 12 ms on localhost (executor driver) (6/11)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 11) in 18 ms on localhost (executor driver) (7/11)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 12) in 14 ms on localhost (executor driver) (8/11)
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_9 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 10) in 21 ms on localhost (executor driver) (9/11)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_9 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 14:
[rdd_23_9]
17/11/20 01:07:17 INFO MemoryStore: Block rdd_23_10 stored as values in memory (estimated size 24.0 B, free 365.9 MB)
17/11/20 01:07:17 INFO BlockManagerInfo: Added rdd_23_10 in memory on 127.0.0.1:64994 (size: 24.0 B, free: 366.2 MB)
17/11/20 01:07:17 INFO Executor: Finished task 9.0 in stage 5.0 (TID 14). 1796 bytes result sent to driver
17/11/20 01:07:17 WARN Executor: 1 block locks were not released by TID = 15:
[rdd_23_10]
17/11/20 01:07:17 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 14) in 8 ms on localhost (executor driver) (10/11)
17/11/20 01:07:17 INFO Executor: Finished task 10.0 in stage 5.0 (TID 15). 1796 bytes result sent to driver
17/11/20 01:07:17 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 15) in 8 ms on localhost (executor driver) (11/11)
17/11/20 01:07:17 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/11/20 01:07:17 INFO DAGScheduler: ResultStage 5 (collect at SpreadRDDBuilder.scala:105) finished in 0.068 s
17/11/20 01:07:17 INFO DAGScheduler: Job 3 finished: collect at SpreadRDDBuilder.scala:105, took 0.075472 s
17/11/20 01:07:17 INFO ParallelCollectionRDD: Removing RDD 23 from persistence list
17/11/20 01:07:17 INFO BlockManager: Removing RDD 23
17/11/20 01:07:17 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/11/20 01:07:17 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/11/20 01:07:18 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/11/20 01:07:18 INFO DAGScheduler: Got job 4 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/11/20 01:07:18 INFO DAGScheduler: Final stage: ResultStage 6 (collect at InternalBackendUtils.scala:163)
17/11/20 01:07:18 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:07:18 INFO DAGScheduler: Missing parents: List()
17/11/20 01:07:18 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at map at InternalBackendUtils.scala:100), which has no missing parents
17/11/20 01:07:18 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.0 KB, free 365.9 MB)
17/11/20 01:07:18 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1961.0 B, free 365.9 MB)
17/11/20 01:07:18 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64994 (size: 1961.0 B, free: 366.2 MB)
17/11/20 01:07:18 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at map at InternalBackendUtils.scala:100)
17/11/20 01:07:18 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/11/20 01:07:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 16, localhost, executor driver, partition 0, ANY, 11562 bytes)
17/11/20 01:07:18 INFO Executor: Running task 0.0 in stage 6.0 (TID 16)
17/11/20 01:07:18 INFO NativeLibrary: Loaded XGBoost library from lib/osx_64/libxgboost4j.dylib (/var/folders/75/kjlw03zd5sqcl30c0cqrq4y80000gn/T/libxgboost4j4298852205113602884.dylib)
17/11/20 01:07:19 INFO Server: jetty-8.1.17.v20150415
17/11/20 01:07:19 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54321
17/11/20 01:07:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 16). 1540 bytes result sent to driver
17/11/20 01:07:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 16) in 1361 ms on localhost (executor driver) (1/1)
17/11/20 01:07:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/11/20 01:07:19 INFO DAGScheduler: ResultStage 6 (collect at InternalBackendUtils.scala:163) finished in 1.363 s
17/11/20 01:07:19 INFO DAGScheduler: Job 4 finished: collect at InternalBackendUtils.scala:163, took 1.372323 s
17/11/20 01:07:19 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/11/20 01:07:19 INFO DAGScheduler: Got job 5 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/11/20 01:07:19 INFO DAGScheduler: Final stage: ResultStage 7 (foreach at InternalBackendUtils.scala:175)
17/11/20 01:07:19 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:07:19 INFO DAGScheduler: Missing parents: List()
17/11/20 01:07:19 INFO DAGScheduler: Submitting ResultStage 7 (InvokeOnNodesRDD[25] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/11/20 01:07:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1672.0 B, free 365.9 MB)
17/11/20 01:07:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1161.0 B, free 365.9 MB)
17/11/20 01:07:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64994 (size: 1161.0 B, free: 366.2 MB)
17/11/20 01:07:19 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (InvokeOnNodesRDD[25] at RDD at InvokeOnNodesRDD.scala:27)
17/11/20 01:07:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/11/20 01:07:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 17, localhost, executor driver, partition 0, ANY, 11562 bytes)
17/11/20 01:07:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 17)
17/11/20 01:07:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 17). 1012 bytes result sent to driver
17/11/20 01:07:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 17) in 7 ms on localhost (executor driver) (1/1)
17/11/20 01:07:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/11/20 01:07:19 INFO DAGScheduler: ResultStage 7 (foreach at InternalBackendUtils.scala:175) finished in 0.008 s
17/11/20 01:07:19 INFO DAGScheduler: Job 5 finished: foreach at InternalBackendUtils.scala:175, took 0.014518 s
17/11/20 01:07:20 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64994 in memory (size: 11.0 KB, free: 366.2 MB)
17/11/20 01:07:20 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64994 in memory (size: 3.7 KB, free: 366.2 MB)
17/11/20 01:07:20 INFO BlockManager: Removing RDD 23
17/11/20 01:07:20 INFO ContextCleaner: Cleaned RDD 23
17/11/20 01:07:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64994 in memory (size: 1361.0 B, free: 366.2 MB)
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 560
17/11/20 01:07:20 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:64994 in memory (size: 1961.0 B, free: 366.3 MB)
17/11/20 01:07:20 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:64994 in memory (size: 1161.0 B, free: 366.3 MB)
17/11/20 01:07:20 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64994 in memory (size: 3.7 KB, free: 366.3 MB)
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 163
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 55
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 56
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 57
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 58
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 59
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 60
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 61
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 62
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 63
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 64
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 65
17/11/20 01:07:20 INFO ContextCleaner: Cleaned accumulator 66
17/11/20 01:07:20 INFO ContextCleaner: Cleaned shuffle 0
17/11/20 01:07:20 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:64994 in memory (size: 11.0 KB, free: 366.3 MB)
17/11/20 01:07:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64994 in memory (size: 4.6 KB, free: 366.3 MB)
17/11/20 01:07:28 INFO ContextCleaner: Cleaned accumulator 1
17/11/20 01:07:28 INFO ContextCleaner: Cleaned accumulator 0
17/11/20 01:07:29 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-Macbook_local-1511140025260
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54321)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54321 (CMD + click in Mac OSX)
    
17/11/20 01:07:29 INFO SparkContext: Starting job: runJob at WriteConverterCtxUtils.scala:85
17/11/20 01:07:29 INFO DAGScheduler: Got job 6 (runJob at WriteConverterCtxUtils.scala:85) with 1 output partitions
17/11/20 01:07:29 INFO DAGScheduler: Final stage: ResultStage 8 (runJob at WriteConverterCtxUtils.scala:85)
17/11/20 01:07:29 INFO DAGScheduler: Parents of final stage: List()
17/11/20 01:07:29 INFO DAGScheduler: Missing parents: List()
17/11/20 01:07:29 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[29] at rdd at SparkDataFrameConverter.scala:59), which has no missing parents
17/11/20 01:07:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 21.4 KB, free 366.0 MB)
17/11/20 01:07:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 10.4 KB, free 365.9 MB)
17/11/20 01:07:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64994 (size: 10.4 KB, free: 366.3 MB)
17/11/20 01:07:29 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/11/20 01:07:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at rdd at SparkDataFrameConverter.scala:59)
17/11/20 01:07:29 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/11/20 01:07:29 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 12134 bytes)
17/11/20 01:07:29 INFO Executor: Running task 0.0 in stage 8.0 (TID 18)
17/11/20 01:07:29 INFO BlockManager: Found block rdd_9_0 locally
17/11/20 01:07:29 INFO CodeGenerator: Code generated in 32.636144 ms
17/11/20 01:07:30 INFO CodeGenerator: Code generated in 21.17608 ms
17/11/20 01:07:30 INFO Executor: Finished task 0.0 in stage 8.0 (TID 18). 1708 bytes result sent to driver
17/11/20 01:07:30 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 18) in 145 ms on localhost (executor driver) (1/1)
17/11/20 01:07:30 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/11/20 01:07:30 INFO DAGScheduler: ResultStage 8 (runJob at WriteConverterCtxUtils.scala:85) finished in 0.145 s
17/11/20 01:07:30 INFO DAGScheduler: Job 6 finished: runJob at WriteConverterCtxUtils.scala:85, took 0.157805 s
17/11/20 01:07:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:07:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:07:30 INFO CodeGenerator: Code generated in 11.503928 ms
17/11/20 01:07:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/11/20 01:07:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/11/20 01:07:31 INFO ContextCleaner: Cleaned accumulator 657
17/11/20 01:07:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64994 in memory (size: 10.4 KB, free: 366.3 MB)
